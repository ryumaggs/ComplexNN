{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "###### cell 0\n",
    "#cell for imports and system variable set ups\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.python.framework import ops\n",
    "#import random\n",
    "import numpy as np\n",
    "from scipy.fft import fft, ifft\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...(1, 4096, 10000)\n",
      "train_y shape:  (10000, 84)\n",
      "(1, 4096, 10000)\n",
      "y batched:  (1, 10000, 84)\n",
      "33362.0\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "###### cell 1:\n",
    "#data loader\n",
    "#note: scipy fft requires the array to be in M x N format, where M = samples, and N = features\n",
    "\n",
    "def load_data(file_var_names):\n",
    "    print(\"Loading data...\", end='')\n",
    "    load_x = np.load(file_var_names[0])\n",
    "    load_y = np.load(file_var_names[1])\n",
    "\n",
    "    #print(Y_complex[0])\n",
    "    train_x = load_x[file_var_names[2]].T\n",
    "    train_y = load_y[file_var_names[3]]\n",
    "\n",
    "    y_value = 1\n",
    "\n",
    "    #ones = [i for i, x in enumerate(train_y) if x == 1]\n",
    "    #zeros = [i for i, x in enumerate(train_y) if x == 0]\n",
    "    #print(ones)\n",
    "    #print(train_x.shape)\n",
    "    #plt.plot(X[0])\n",
    "    #plt.show()\n",
    "\n",
    "    print(train_x.shape)\n",
    "    print(\"train_y shape: \", train_y.shape)\n",
    "    num_batch = 1\n",
    "    samples_per_batch = train_x.shape[2]//num_batch\n",
    "    train_x_fft = np.zeros((num_batch, train_x.shape[1], samples_per_batch)).astype('complex64')\n",
    "    train_y_batched = np.zeros((num_batch, samples_per_batch,train_y.shape[1]))\n",
    "    print(train_x_fft.shape)\n",
    "    print(\"y batched: \", train_y_batched.shape)\n",
    "    cur_batch = 0\n",
    "    cur_sample = 0\n",
    "    for col in range(train_x_fft.shape[2]):\n",
    "        fftx = np.fft.fft(train_x[0,:,col])\n",
    "        real_data = np.real(fftx)\n",
    "        imag_data = np.imag(fftx)\n",
    "        #real_data = ( real_data - real_data.mean() ) / real_data.std()\n",
    "        #imag_data = ( imag_data - imag_data.mean() ) / imag_data.std()\n",
    "        x_source_norm = real_data + imag_data*1j\n",
    "        train_x_fft[cur_batch,:,cur_sample] = x_source_norm\n",
    "        train_y_batched[cur_batch,cur_sample,:] = train_y[col,:]\n",
    "        if cur_sample >= samples_per_batch:\n",
    "            cur_batch += 1\n",
    "            cur_sample = 0\n",
    "        if cur_batch >= num_batch:\n",
    "            break\n",
    "        cur_sample += 1\n",
    "\n",
    "    train_x = tf.convert_to_tensor(train_x_fft,dtype='complex64')\n",
    "    print(np.sum(train_y.flatten()))\n",
    "    train_y = tf.cast(train_y_batched,dtype='float32')\n",
    "    print(\"Done\")\n",
    "    return train_x, train_y\n",
    "train_x, train_y = load_data(['./train_x.npz', './train_y.npz', 'train_x', 'train_y'])\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-7.32182443e-01+0.j          6.12951592e-02+0.j\n",
      "    4.18733180e-01+0.j         ... -2.01207459e-01+0.j\n",
      "    1.66948724e+00+0.j          1.66138951e-02+0.j        ]\n",
      "  [-8.62999678e-01-0.0891651j   2.79659554e-02+0.00613794j\n",
      "    4.48797882e-01+0.03152297j ...  8.31077278e-01-0.13428916j\n",
      "   -3.74569356e-01-0.9135404j   1.15788646e-01+0.00239535j]\n",
      "  [-3.58897984e-01+0.05327325j -1.56238116e-03-0.06451115j\n",
      "    4.25156295e-01+0.0040571j  ...  3.30463946e-01+0.08992868j\n",
      "    1.19004071e+00+0.20340359j  4.74000946e-02-0.02612199j]\n",
      "  ...\n",
      "  [-4.59978044e-01-0.22489417j  6.57720715e-02-0.00539386j\n",
      "    4.35869277e-01+0.04393807j ...  3.31263505e-02+0.37653005j\n",
      "    3.07998627e-01-0.45818123j  7.53297657e-02+0.02720537j]\n",
      "  [-3.58897984e-01-0.05327325j -1.56238116e-03+0.06451115j\n",
      "    4.25156295e-01-0.0040571j  ...  3.30463946e-01-0.08992868j\n",
      "    1.19004071e+00-0.20340359j  4.74000946e-02+0.02612199j]\n",
      "  [-8.62999678e-01+0.0891651j   2.79659554e-02-0.00613794j\n",
      "    4.48797882e-01-0.03152297j ...  8.31077278e-01+0.13428916j\n",
      "   -3.74569356e-01+0.9135404j   1.15788646e-01-0.00239535j]]], shape=(1, 4096, 10000), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "###### cell 2:\n",
    "#helper functions\n",
    "complex_dtype = 'complex64'\n",
    "def cReLU(x):\n",
    "    #print(x)\n",
    "    ret_real = tf.math.real(x)\n",
    "    ret_imag = tf.math.imag(x)\n",
    "    ret_real = tf.nn.relu(ret_real)\n",
    "    ret_imag = tf.nn.relu(ret_imag)\n",
    "    return tf.complex(ret_real,ret_imag)\n",
    "np_cReLU = np.vectorize(cReLU)\n",
    "\n",
    "def P2C(radii, angles):\n",
    "    x = tf.multiply(radii, tf.math.cos(angles))\n",
    "    y = tf.multiply(radii, tf.math.sin(angles))\n",
    "    return tf.cast(tf.complex(x,y),dtype='complex64')\n",
    "\n",
    "y = tf.constant([2.0, 8.0])\n",
    "x = tf.constant([2.0, 8.0])\n",
    "\n",
    "#print(P2C(y,x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class ComplexDenseLayer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,input_dim,num_outputs,activation):\n",
    "        super(ComplexDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        real = np.random.randn(input_dim, self.num_outputs) * np.sqrt(2/self.num_outputs)\n",
    "        imag = np.random.randn(input_dim, self.num_outputs) * np.sqrt(2/self.num_outputs)\n",
    "        complex_mat = tf.cast(tf.complex(real,imag),complex_dtype)\n",
    "        self.w = tf.Variable(complex_mat, dtype=complex_dtype,trainable=True)\n",
    "        bias_real = np.random.rand(self.num_outputs,1)\n",
    "        bias_imag = np.random.rand(self.num_outputs,1)\n",
    "        bias_complex = tf.cast(tf.complex(bias_real, bias_imag),complex_dtype)\n",
    "        self.b = tf.Variable(bias_complex,dtype=complex_dtype,trainable=True)\n",
    "        self.activation=activation\n",
    "\n",
    "    def call(self,inputs):\n",
    "        batch_b = tf.repeat(self.b,inputs.shape[1],1)\n",
    "        out = tf.matmul(tf.transpose(self.w),inputs)+batch_b\n",
    "        if self.activation==\"phase\":\n",
    "            out = tf.convert_to_tensor(P2C(tf.math.abs(out)*0.5,tf.math.angle(out)),dtype='complex64')\n",
    "            out += tf.convert_to_tensor(P2C(tf.matmul(tf.transpose(tf.math.abs(self.w)),tf.math.abs(inputs)*0.5),tf.math.angle(out)),dtype='complex64')\n",
    "            out += batch_b\n",
    "        #print(type(out))\n",
    "        return out\n",
    "\n",
    "class Complex1DConvLayer(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, stride, padding, kernel_size):\n",
    "        output_shape = (input_dim-kernel_size + 2*padding)/stride\n",
    "    def call(self,inputs):\n",
    "        batch_b = tf.repeat(self.b, inputs.shape[1],1)\n",
    "        return tf.matmul(tf.transpose(self.w), inputs)+batch_b\n",
    "\n",
    "class Complex1DMaxPool(keras.layers.Layer):\n",
    "    def __init__(self,input_dim,stride,padding,kernel_size):\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_shape = (input_dim-kernel_size + 2*padding)/stride\n",
    "    def call(self,inputs):\n",
    "        #assumes data is given as features x samples\n",
    "        out = tf.convert_to_tensor(np.zeros((self.out_shape, inputs.shape[1])) + np.zeros((self.out_shape, inputs.shape[1]))*1j, dtype='complex64')\n",
    "        for sample in range(inputs.shape[1]):\n",
    "            out[:,sample] = tf.convert_to_tensor(maxMagnitude(inputs[:,sample].numpy()), dtype='complex64')\n",
    "        return out\n",
    "        \n",
    "    def MaxMagnitude(sample):\n",
    "        #assumes that sample is given as a numpy array\n",
    "        max_pooled = np.zeros((self.out_shape,1)) + np.zeros((self.out_shape,1))*1j\n",
    "        sample_mag = abs(sample)\n",
    "        out_index = 0\n",
    "        kernel_start = 0\n",
    "        while(out_index < max_pooled.shape[0]):\n",
    "            max_pooled[out_index] = sample[kernel_start + np.argmax(sample_mag[kernel_start:kernel_start+self.kernel_size])]\n",
    "            out_index += 1\n",
    "            kernel_start += self.stride\n",
    "        return max_pooled\n",
    "\n",
    "class ComplexFCNetwork(keras.Model):\n",
    "    def __init__(self, dimensions, activation, name=\"ComplexValueFC\", **kwargs):\n",
    "        super(ComplexFCNetwork, self).__init__(name=name,**kwargs)\n",
    "        self.specs = str(dimensions)\n",
    "        complex_dimensions = dimensions[0]\n",
    "        real_dimensions = dimensions[1]\n",
    "        self.orig_shape = complex_dimensions[0]\n",
    "        self.layerz = []\n",
    "        self.m = []\n",
    "        self.v = []\n",
    "        self.num_complex_layers = len(complex_dimensions) - 1\n",
    "        self.num_real_layers = len(real_dimensions)\n",
    "        #complex layers\n",
    "        for index in range(len(complex_dimensions)-1):\n",
    "            self.layerz.append(ComplexDenseLayer(complex_dimensions[index],complex_dimensions[index+1],activation))\n",
    "            #weight momentum\n",
    "            self.m.append(np.zeros((complex_dimensions[index],complex_dimensions[index+1]))+np.zeros((complex_dimensions[index],complex_dimensions[index+1]))*1j)\n",
    "            self.v.append(np.zeros((complex_dimensions[index],complex_dimensions[index+1]))+np.zeros((complex_dimensions[index],complex_dimensions[index+1]))*1j)\n",
    "            #bias momentum\n",
    "            self.m.append(np.zeros((complex_dimensions[index+1],1)))\n",
    "            self.v.append(np.zeros((complex_dimensions[index+1],1)))\n",
    "        #complex-real transition\n",
    "        act = 'sigmoid'\n",
    "        if len(real_dimensions) > 1:\n",
    "            act = 'relu'\n",
    "            \n",
    "        self.layerz.append(tf.keras.layers.Dense(real_dimensions[0],activation=act))\n",
    "        self.m.append(np.zeros((complex_dimensions[-1]*2, real_dimensions[0])))\n",
    "        self.v.append(np.zeros((complex_dimensions[-1]*2, real_dimensions[0])))\n",
    "        #bias momentum\n",
    "        self.m.append(np.zeros((real_dimensions[0])))\n",
    "        self.v.append(np.zeros((real_dimensions[0])))\n",
    "        if len(real_dimensions) > 1:\n",
    "            real_index = 1\n",
    "            while(real_index < len(real_dimensions)):\n",
    "                #print(\"real: \", real_index)\n",
    "                if (real_index +1) >= len(real_dimensions):\n",
    "                    act = 'sigmoid'\n",
    "                else:\n",
    "                    act = 'relu'\n",
    "                #print(\"ading layer: \", real_dimensions[real_index])\n",
    "                self.layerz.append(tf.keras.layers.Dense(real_dimensions[real_index],activation=act))\n",
    "                self.m.append(np.zeros((real_dimensions[real_index-1], real_dimensions[real_index])))\n",
    "                self.v.append(np.zeros((real_dimensions[real_index-1],real_dimensions[real_index])))\n",
    "                #bias momentum\n",
    "                self.m.append(np.zeros((real_dimensions[real_index])))\n",
    "                self.v.append(np.zeros((real_dimensions[real_index])))\n",
    "                real_index += 1\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #print(\"self.layerz: \", self.layerz)\n",
    "        ret = inputs\n",
    "        index = 0\n",
    "        '''print(ret.shape)\n",
    "        print(\"input: \", ret)\n",
    "        print(\"\")\n",
    "        foi = 1'''\n",
    "        while index < self.num_complex_layers:\n",
    "            '''to_plot = ret[foi,:].numpy()\n",
    "            X = np.real(to_plot)\n",
    "            Y = np.imag(to_plot)\n",
    "            plt.scatter(X,Y,color='red')\n",
    "            plt.show()\n",
    "            print(\"real: \", X)\n",
    "            print(\"imag; \", Y)'''\n",
    "            ret = cReLU((self.layerz[index])(ret))\n",
    "            index += 1\n",
    "        '''to_plot = ret[foi,:].numpy()\n",
    "        X = np.real(to_plot)\n",
    "        Y = np.imag(to_plot)\n",
    "        plt.scatter(X,Y,color='red')\n",
    "        plt.show()\n",
    "        print(\"real: \", X)\n",
    "        print(\"imag; \", Y)'''\n",
    "        #ret_real = tf.math.real(ret)\n",
    "        #ret_imag = tf.math.imag(ret)\n",
    "        #ret = tf.transpose(tf.concat([ret_real,ret_imag],0))\n",
    "        ret_r = tf.math.real(ret)\n",
    "        ret_phi = tf.math.imag(ret)\n",
    "        ret = tf.concat([ret_r,ret_phi],0)\n",
    "        '''print(\"mag: \", ret_r)\n",
    "        print(\"\")\n",
    "        print(\"phase: \", ret_phi)\n",
    "        print(\"\")\n",
    "        #ret = tf.transpose(ret)\n",
    "        print(\"transition: \", ret)'''\n",
    "        ret = tf.transpose(ret)\n",
    "        '''print(\"\")\n",
    "        print(\"tranposed: \", ret)'''\n",
    "        \n",
    "        while index < (self.num_complex_layers + self.num_real_layers):\n",
    "            #print(\"passing through dense\")\n",
    "            ret = (self.layerz[index])(ret)\n",
    "            #print(\"layer\", index, \":\", ret)\n",
    "            #print(\"dense shapes: \", ret.shape)\n",
    "            index += 1\n",
    "        return ret\n",
    "\n",
    "def cadam(lr,grad,m,v,t):\n",
    "    #print(\"m: \", m.shape)\n",
    "    #print(\"v: \", v.shape)\n",
    "    #print(\"grad: \", grad.shape)\n",
    "    b1 = 0.9\n",
    "    b2 = 0.999\n",
    "    epsilon = .0001\n",
    "    m = b1 * m + (1 - b1) * (grad)\n",
    "    v = b2 * v + (1 - b2) * (np.power(grad,2))\n",
    "    m_hat = m/(1-np.power(b1,t+1))\n",
    "    v_hat = v/(1-np.power(b2,t+1))\n",
    "    return lr*m_hat/(np.sqrt(v_hat)+epsilon)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#validation cell\n",
    "def validate(model, val_x, val_y, mse_loss_fn):\n",
    "    epochs = 1\n",
    "    test_out = []\n",
    "    loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(val_x.shape[0]):\n",
    "            x = val_x[batch,:,:]\n",
    "            y = val_y[batch,:,:]\n",
    "            y_hat = model(x)\n",
    "            loss = mse_loss_fn(y, tf.math.real(y_hat))\n",
    "    return loss\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_x, test_y):\n",
    "    for batch in range(test_x.shape[0]):\n",
    "        y_hat = model(test_x[batch,:,:])\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random data cell\n",
    "def rand_bin_array(K, N, M):\n",
    "    arr = np.zeros(N*M)\n",
    "    arr[:K]  = 1\n",
    "    np.random.shuffle(arr)\n",
    "    return np.reshape(arr, (1,N,M))\n",
    "\n",
    "def load_random_data(shape,out_shape):\n",
    "    #shape is a tuple that dictates the input shape\n",
    "    real = np.random.random(shape)\n",
    "    imag = np.random.random(shape)\n",
    "    fake_input = tf.convert_to_tensor(real + imag*1j,dtype='complex64')\n",
    "    return tf.reshape(fake_input,(1,fake_input.shape[0],fake_input.shape[1])), rand_bin_array(0,shape[1],out_shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 8.], shape=(2,), dtype=float32)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(type(np.where(y > 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#cell 3:\n",
    "#main training/testing function\n",
    "def main(train=True, dimensions=[], act=\"standard\", model = None, train_filenames=['./train_x.npz', './train_y.npz', 'train_x', 'train_y'], valid_filenames=['./test_x.npz', './test_y.npz', 'test_x', 'test_y']):\n",
    "    train_x, train_y = load_data(train_filenames)\n",
    "    #train_x, train_y = load_random_data((dimensions[0][0],1000),dimensions[1][-1])\n",
    "    #valid_filenames = None\n",
    "    val_x = None\n",
    "    val_y = None\n",
    "    if valid_filenames != None:\n",
    "        val_x, val_y = load_data(valid_filenames)\n",
    "    if model == None:\n",
    "        print(\"made new model!\")\n",
    "        model = ComplexFCNetwork(dimensions,activation=act)\n",
    "\n",
    "    mse_loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "    learning_rate = 0.005\n",
    "    epochs = 500\n",
    "    if train == False:\n",
    "        epochs = 1\n",
    "    eta = 1\n",
    "    loss_arr = []\n",
    "    val_loss_arr = []\n",
    "    truths = []\n",
    "    falses = []\n",
    "    test_out = 0\n",
    "    last = None\n",
    "    for epoch in range(epochs):\n",
    "        print(\"beginning \", epoch, \": \", end = '')\n",
    "        for batch in range(train_x.shape[0]):\n",
    "            num_points = 100\n",
    "            x = train_x[batch,:,:]\n",
    "            y = train_y[batch,:,:]\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_hat = model(x)\n",
    "                test_out = y_hat\n",
    "                '''print(\"\")\n",
    "                print(\"1s: \", [y_hat[0][i].numpy() for i in np.where(y[0] >= 1)[0]])\n",
    "                print(\"2s: \", [y_hat[1][i].numpy() for i in np.where(y[0] >= 1)[0]])\n",
    "                print(\"3s: \", [y_hat[2][i].numpy() for i in np.where(y[0] >= 1)[0]])\n",
    "                print(\"\")\n",
    "                #print(\"0s: \", [y_hat[0][i].numpy() for i in np.where(y[0] <= 0)[0]])\n",
    "                print(\"y1: \", np.where(y[0] >= 1)[0])\n",
    "                print(\"y2: \", np.where(y[1] >= 1)[0])\n",
    "                print(\"y3: \", np.where(y[2] >= 1)[0])\n",
    "                print(\"\")'''\n",
    "                loss = mse_loss_fn(y, tf.math.real(y_hat))\n",
    "                if epoch+1 == epochs: #saves the final output of our network\n",
    "                    test_out = y_hat\n",
    "            #print(\"Tape:\", tape)\n",
    "            if train == True:\n",
    "                grads = tape.gradient(loss, model.trainable_weights)\n",
    "                #print(\"grads: \", grads)\n",
    "                #print(\"weights: \", model.trainable_weights[0])\n",
    "                for i in range(len(model.trainable_weights)):\n",
    "                    #print(\"I: \", i)\n",
    "                    #cadam_grad = cadam(learning_rate,grads[i],model.m[i], model.v[i], epoch+1)\n",
    "                    #tf.compat.v1.assign(model.trainable_weights[i],tf.math.subtract(model.trainable_weights[i]*eta,cadam_grad))\n",
    "                    tf.compat.v1.assign(model.trainable_weights[i],tf.math.subtract(model.trainable_weights[i]*eta,learning_rate*grads[i]))\n",
    "            print(\"x\", end='')\n",
    "        print(\"\")\n",
    "        if train == True and ((epoch) %20 == 0 or epoch == epochs):\n",
    "            print(\"loss: \", loss.numpy())\n",
    "            val_loss = None\n",
    "            loss_arr.append(loss.numpy())\n",
    "            if valid_filenames != None:\n",
    "                print(\"validating...\", end='')\n",
    "                val_loss = validate(model,val_x, val_y, mse_loss_fn)\n",
    "                print('x')\n",
    "                print(\"Validation loss: \", val_loss)\n",
    "                val_loss_arr.append(val_loss)\n",
    "            #print(\"saving model...\", end='')\n",
    "            #model.save_weights('./weights/depthTest.ckpt')\n",
    "            #print(\"Done\",end='\\n')\n",
    "    \n",
    "    print(\"Done\")\n",
    "    return test_out, train_y, loss_arr, val_loss_arr, model\n",
    "\n",
    "#np.savez(\"./models/singlepointloss.npz\", loss_arr=loss_arr)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 6\n",
    "#analysis cell\n",
    "\n",
    "def convert_to_binary(y_hat,thresh, y_value = 1):\n",
    "    return np.where(y_hat > thresh, y_value, 0)\n",
    "\n",
    "def metrics2(y_hat, truth, y_value = 1):\n",
    "    #print(\"y_hat\", y_hat)\n",
    "    #print(\"truth\", truth)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for feature in range(len(y_hat)):\n",
    "        for sample in range(len(y_hat[feature])):\n",
    "            if y_hat[feature][sample] == 0 and truth[feature][sample] == 0:\n",
    "                tn += 1\n",
    "            elif y_hat[feature][sample] == 0 and truth[feature][sample] == y_value:\n",
    "                fn += 1\n",
    "            elif y_hat[feature][sample] == y_value and truth[feature][sample] == 0:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "    return tp, fp, fn, tn\n",
    "def analysis(train_test, train_y, y_value = 1):\n",
    "    list_to_numpy = [train_test[0].numpy()]\n",
    "    i = 1\n",
    "    while ( i < len(train_test)):\n",
    "        list_to_numpy.append(train_test[i].numpy())\n",
    "        i += 1\n",
    "\n",
    "    numpy_to_tensor = (np.reshape(np.asarray(list_to_numpy),(1,len(list_to_numpy),list_to_numpy[0].shape[0])))\n",
    "\n",
    "    train_test_2 = tf.convert_to_tensor(numpy_to_tensor)\n",
    "\n",
    "    print(train_test_2.shape)\n",
    "    #train_test_2 = tf.convert_to_tensor(np.concatenate((train_test[0].numpy(),train_test[1].numpy()),axis=1))\n",
    "    #print(train_test_2.shape)\n",
    "    recall_arr = []\n",
    "    precision_arr = []\n",
    "    print(train_y.shape)\n",
    "    batch = 0\n",
    "    AP = 0\n",
    "    best_prec = 0\n",
    "    best_recall = 0\n",
    "    best_half = 0\n",
    "    while batch < train_y.shape[0]:\n",
    "        cur_thresh = 0\n",
    "        while(cur_thresh < 1):\n",
    "            #print(cur_thresh)\n",
    "            bin_y_hat = convert_to_binary(train_test_2,cur_thresh).astype(np.float32)\n",
    "            #print(bin_y_hat.shape)\n",
    "            compare = train_y.numpy()\n",
    "            #print(compare.shape)\n",
    "            #print(bin_y_hat[batch].shape)\n",
    "            tp, fp, fn, tn = metrics(bin_y_hat[batch],compare[batch])\n",
    "\n",
    "            print(\"tp: \", tp, \"fp: \", fp, \"fn: \", fn, \"tn: \", tn)\n",
    "            \n",
    "            accuracy = (tp + tn) / (len(bin_y_hat)*len(bin_y_hat[0]))\n",
    "            if (tp + fp) == 0:\n",
    "                cur_thresh += 0.02\n",
    "                break\n",
    "            if (tp + fn) == 0:\n",
    "                cur_thresh += 0.02\n",
    "                continue\n",
    "            precision = (tp) / (tp + fp)\n",
    "            recall = (tp) / (tp + fn)\n",
    "            half = precision * 0.75 + recall*0.25\n",
    "            if half > best_half:\n",
    "                best_half = half\n",
    "                best_prec = precision\n",
    "                best_recall = recall\n",
    "            print(\"recall: \", recall, \" precision: \", precision)\n",
    "            if cur_thresh != 0:\n",
    "                AP += -1*(recall-recall_arr[-1])*precision\n",
    "            recall_arr.append(recall)\n",
    "            precision_arr.append(precision)\n",
    "            cur_thresh += 0.02\n",
    "        batch += 1\n",
    "\n",
    "    #print(\"Accuracy: \", accuracy, \"|| Precision: \", precision, \"|| Recall: \", recall)\n",
    "    #print(precision_arr, recall_arr)\n",
    "    print(\"Best Precision: \", best_prec)\n",
    "    print(\"Best recall: \", best_recall)\n",
    "    return recall_arr, precision_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...(1, 4096, 10000)\n",
      "train_y shape:  (10000, 84)\n",
      "(1, 4096, 10000)\n",
      "y batched:  (1, 10000, 84)\n",
      "33362.0\n",
      "Done\n",
      "Loading data...(1, 4096, 2000)\n",
      "train_y shape:  (2000, 84)\n",
      "(1, 4096, 2000)\n",
      "y batched:  (1, 2000, 84)\n",
      "6780.0\n",
      "Done\n",
      "made new model!\n",
      "beginning  0 : x\n",
      "loss:  5.0689526\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(4.5907426, shape=(), dtype=float32)\n",
      "beginning  1 : x\n",
      "beginning  2 : x\n",
      "beginning  3 : x\n",
      "beginning  4 : x\n",
      "beginning  5 : x\n",
      "beginning  6 : x\n",
      "beginning  7 : x\n",
      "beginning  8 : x\n",
      "beginning  9 : x\n",
      "beginning  10 : x\n",
      "beginning  11 : x\n",
      "beginning  12 : x\n",
      "beginning  13 : x\n",
      "beginning  14 : x\n",
      "beginning  15 : x\n",
      "beginning  16 : x\n",
      "beginning  17 : x\n",
      "beginning  18 : x\n",
      "beginning  19 : x\n",
      "beginning  20 : x\n",
      "loss:  1.1987185\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(1.1607808, shape=(), dtype=float32)\n",
      "beginning  21 : x\n",
      "beginning  22 : x\n",
      "beginning  23 : x\n",
      "beginning  24 : x\n",
      "beginning  25 : x\n",
      "beginning  26 : x\n",
      "beginning  27 : x\n",
      "beginning  28 : x\n",
      "beginning  29 : x\n",
      "beginning  30 : x\n",
      "beginning  31 : x\n",
      "beginning  32 : x\n",
      "beginning  33 : x\n",
      "beginning  34 : x\n",
      "beginning  35 : x\n",
      "beginning  36 : x\n",
      "beginning  37 : x\n",
      "beginning  38 : x\n",
      "beginning  39 : x\n",
      "beginning  40 : x\n",
      "loss:  0.9156982\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.9150142, shape=(), dtype=float32)\n",
      "beginning  41 : x\n",
      "beginning  42 : x\n",
      "beginning  43 : x\n",
      "beginning  44 : x\n",
      "beginning  45 : x\n",
      "beginning  46 : x\n",
      "beginning  47 : x\n",
      "beginning  48 : x\n",
      "beginning  49 : x\n",
      "beginning  50 : x\n",
      "beginning  51 : x\n",
      "beginning  52 : x\n",
      "beginning  53 : x\n",
      "beginning  54 : x\n",
      "beginning  55 : x\n",
      "beginning  56 : x\n",
      "beginning  57 : x\n",
      "beginning  58 : x\n",
      "beginning  59 : x\n",
      "beginning  60 : x\n",
      "loss:  0.636199\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.6339387, shape=(), dtype=float32)\n",
      "beginning  61 : x\n",
      "beginning  62 : x\n",
      "beginning  63 : x\n",
      "beginning  64 : x\n",
      "beginning  65 : x\n",
      "beginning  66 : x\n",
      "beginning  67 : x\n",
      "beginning  68 : x\n",
      "beginning  69 : x\n",
      "beginning  70 : x\n",
      "beginning  71 : x\n",
      "beginning  72 : x\n",
      "beginning  73 : x\n",
      "beginning  74 : x\n",
      "beginning  75 : x\n",
      "beginning  76 : x\n",
      "beginning  77 : x\n",
      "beginning  78 : x\n",
      "beginning  79 : x\n",
      "beginning  80 : x\n",
      "loss:  0.5729231\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5828723, shape=(), dtype=float32)\n",
      "beginning  81 : x\n",
      "beginning  82 : x\n",
      "beginning  83 : x\n",
      "beginning  84 : x\n",
      "beginning  85 : x\n",
      "beginning  86 : x\n",
      "beginning  87 : x\n",
      "beginning  88 : x\n",
      "beginning  89 : x\n",
      "beginning  90 : x\n",
      "beginning  91 : x\n",
      "beginning  92 : x\n",
      "beginning  93 : x\n",
      "beginning  94 : x\n",
      "beginning  95 : x\n",
      "beginning  96 : x\n",
      "beginning  97 : x\n",
      "beginning  98 : x\n",
      "beginning  99 : x\n",
      "beginning  100 : x\n",
      "loss:  0.5627991\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.57409745, shape=(), dtype=float32)\n",
      "beginning  101 : x\n",
      "beginning  102 : x\n",
      "beginning  103 : x\n",
      "beginning  104 : x\n",
      "beginning  105 : x\n",
      "beginning  106 : x\n",
      "beginning  107 : x\n",
      "beginning  108 : x\n",
      "beginning  109 : x\n",
      "beginning  110 : x\n",
      "beginning  111 : x\n",
      "beginning  112 : x\n",
      "beginning  113 : x\n",
      "beginning  114 : x\n",
      "beginning  115 : x\n",
      "beginning  116 : x\n",
      "beginning  117 : x\n",
      "beginning  118 : x\n",
      "beginning  119 : x\n",
      "beginning  120 : x\n",
      "loss:  0.5568528\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5695469, shape=(), dtype=float32)\n",
      "beginning  121 : x\n",
      "beginning  122 : x\n",
      "beginning  123 : x\n",
      "beginning  124 : x\n",
      "beginning  125 : x\n",
      "beginning  126 : x\n",
      "beginning  127 : x\n",
      "beginning  128 : x\n",
      "beginning  129 : x\n",
      "beginning  130 : x\n",
      "beginning  131 : x\n",
      "beginning  132 : x\n",
      "beginning  133 : x\n",
      "beginning  134 : x\n",
      "beginning  135 : x\n",
      "beginning  136 : x\n",
      "beginning  137 : x\n",
      "beginning  138 : x\n",
      "beginning  139 : x\n",
      "beginning  140 : x\n",
      "loss:  0.5525537\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5665404, shape=(), dtype=float32)\n",
      "beginning  141 : x\n",
      "beginning  142 : x\n",
      "beginning  143 : x\n",
      "beginning  144 : x\n",
      "beginning  145 : x\n",
      "beginning  146 : x\n",
      "beginning  147 : x\n",
      "beginning  148 : x\n",
      "beginning  149 : x\n",
      "beginning  150 : x\n",
      "beginning  151 : x\n",
      "beginning  152 : x\n",
      "beginning  153 : x\n",
      "beginning  154 : x\n",
      "beginning  155 : x\n",
      "beginning  156 : x\n",
      "beginning  157 : x\n",
      "beginning  158 : x\n",
      "beginning  159 : x\n",
      "beginning  160 : x\n",
      "loss:  0.548943\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.56422913, shape=(), dtype=float32)\n",
      "beginning  161 : x\n",
      "beginning  162 : x\n",
      "beginning  163 : x\n",
      "beginning  164 : x\n",
      "beginning  165 : x\n",
      "beginning  166 : x\n",
      "beginning  167 : x\n",
      "beginning  168 : x\n",
      "beginning  169 : x\n",
      "beginning  170 : x\n",
      "beginning  171 : x\n",
      "beginning  172 : x\n",
      "beginning  173 : x\n",
      "beginning  174 : x\n",
      "beginning  175 : x\n",
      "beginning  176 : x\n",
      "beginning  177 : x\n",
      "beginning  178 : x\n",
      "beginning  179 : x\n",
      "beginning  180 : x\n",
      "loss:  0.5457781\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.56224996, shape=(), dtype=float32)\n",
      "beginning  181 : x\n",
      "beginning  182 : x\n",
      "beginning  183 : x\n",
      "beginning  184 : x\n",
      "beginning  185 : x\n",
      "beginning  186 : x\n",
      "beginning  187 : x\n",
      "beginning  188 : x\n",
      "beginning  189 : x\n",
      "beginning  190 : x\n",
      "beginning  191 : x\n",
      "beginning  192 : x\n",
      "beginning  193 : x\n",
      "beginning  194 : x\n",
      "beginning  195 : x\n",
      "beginning  196 : x\n",
      "beginning  197 : x\n",
      "beginning  198 : x\n",
      "beginning  199 : x\n",
      "beginning  200 : x\n",
      "loss:  0.5430674\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5605372, shape=(), dtype=float32)\n",
      "beginning  201 : x\n",
      "beginning  202 : x\n",
      "beginning  203 : x\n",
      "beginning  204 : x\n",
      "beginning  205 : x\n",
      "beginning  206 : x\n",
      "beginning  207 : x\n",
      "beginning  208 : x\n",
      "beginning  209 : x\n",
      "beginning  210 : x\n",
      "beginning  211 : x\n",
      "beginning  212 : x\n",
      "beginning  213 : x\n",
      "beginning  214 : x\n",
      "beginning  215 : x\n",
      "beginning  216 : x\n",
      "beginning  217 : x\n",
      "beginning  218 : x\n",
      "beginning  219 : x\n",
      "beginning  220 : x\n",
      "loss:  0.54053307\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5589617, shape=(), dtype=float32)\n",
      "beginning  221 : x\n",
      "beginning  222 : x\n",
      "beginning  223 : x\n",
      "beginning  224 : x\n",
      "beginning  225 : x\n",
      "beginning  226 : x\n",
      "beginning  227 : x\n",
      "beginning  228 : x\n",
      "beginning  229 : x\n",
      "beginning  230 : x\n",
      "beginning  231 : x\n",
      "beginning  232 : x\n",
      "beginning  233 : x\n",
      "beginning  234 : x\n",
      "beginning  235 : x\n",
      "beginning  236 : x\n",
      "beginning  237 : x\n",
      "beginning  238 : x\n",
      "beginning  239 : x\n",
      "beginning  240 : x\n",
      "loss:  0.5381451\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.557491, shape=(), dtype=float32)\n",
      "beginning  241 : x\n",
      "beginning  242 : x\n",
      "beginning  243 : x\n",
      "beginning  244 : x\n",
      "beginning  245 : x\n",
      "beginning  246 : x\n",
      "beginning  247 : x\n",
      "beginning  248 : x\n",
      "beginning  249 : x\n",
      "beginning  250 : x\n",
      "beginning  251 : x\n",
      "beginning  252 : x\n",
      "beginning  253 : x\n",
      "beginning  254 : x\n",
      "beginning  255 : x\n",
      "beginning  256 : x\n",
      "beginning  257 : x\n",
      "beginning  258 : x\n",
      "beginning  259 : x\n",
      "beginning  260 : x\n",
      "loss:  0.535868\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.55609185, shape=(), dtype=float32)\n",
      "beginning  261 : x\n",
      "beginning  262 : x\n",
      "beginning  263 : x\n",
      "beginning  264 : x\n",
      "beginning  265 : x\n",
      "beginning  266 : x\n",
      "beginning  267 : x\n",
      "beginning  268 : x\n",
      "beginning  269 : x\n",
      "beginning  270 : x\n",
      "beginning  271 : x\n",
      "beginning  272 : x\n",
      "beginning  273 : x\n",
      "beginning  274 : x\n",
      "beginning  275 : x\n",
      "beginning  276 : x\n",
      "beginning  277 : x\n",
      "beginning  278 : x\n",
      "beginning  279 : x\n",
      "beginning  280 : x\n",
      "loss:  0.53366965\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.55474454, shape=(), dtype=float32)\n",
      "beginning  281 : x\n",
      "beginning  282 : x\n",
      "beginning  283 : x\n",
      "beginning  284 : x\n",
      "beginning  285 : x\n",
      "beginning  286 : x\n",
      "beginning  287 : x\n",
      "beginning  288 : x\n",
      "beginning  289 : x\n",
      "beginning  290 : x\n",
      "beginning  291 : x\n",
      "beginning  292 : x\n",
      "beginning  293 : x\n",
      "beginning  294 : x\n",
      "beginning  295 : x\n",
      "beginning  296 : x\n",
      "beginning  297 : x\n",
      "beginning  298 : x\n",
      "beginning  299 : x\n",
      "beginning  300 : x\n",
      "loss:  0.5315602\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.55344975, shape=(), dtype=float32)\n",
      "beginning  301 : x\n",
      "beginning  302 : x\n",
      "beginning  303 : x\n",
      "beginning  304 : x\n",
      "beginning  305 : x\n",
      "beginning  306 : x\n",
      "beginning  307 : x\n",
      "beginning  308 : x\n",
      "beginning  309 : x\n",
      "beginning  310 : x\n",
      "beginning  311 : x\n",
      "beginning  312 : x\n",
      "beginning  313 : x\n",
      "beginning  314 : x\n",
      "beginning  315 : x\n",
      "beginning  316 : x\n",
      "beginning  317 : x\n",
      "beginning  318 : x\n",
      "beginning  319 : x\n",
      "beginning  320 : x\n",
      "loss:  0.529522\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5522218, shape=(), dtype=float32)\n",
      "beginning  321 : x\n",
      "beginning  322 : x\n",
      "beginning  323 : x\n",
      "beginning  324 : x\n",
      "beginning  325 : x\n",
      "beginning  326 : x\n",
      "beginning  327 : x\n",
      "beginning  328 : x\n",
      "beginning  329 : x\n",
      "beginning  330 : x\n",
      "beginning  331 : x\n",
      "beginning  332 : x\n",
      "beginning  333 : x\n",
      "beginning  334 : x\n",
      "beginning  335 : x\n",
      "beginning  336 : x\n",
      "beginning  337 : x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning  338 : x\n",
      "beginning  339 : x\n",
      "beginning  340 : x\n",
      "loss:  0.5275339\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.55103505, shape=(), dtype=float32)\n",
      "beginning  341 : x\n",
      "beginning  342 : x\n",
      "beginning  343 : x\n",
      "beginning  344 : x\n",
      "beginning  345 : x\n",
      "beginning  346 : x\n",
      "beginning  347 : x\n",
      "beginning  348 : x\n",
      "beginning  349 : x\n",
      "beginning  350 : x\n",
      "beginning  351 : x\n",
      "beginning  352 : x\n",
      "beginning  353 : x\n",
      "beginning  354 : x\n",
      "beginning  355 : x\n",
      "beginning  356 : x\n",
      "beginning  357 : x\n",
      "beginning  358 : x\n",
      "beginning  359 : x\n",
      "beginning  360 : x\n",
      "loss:  0.5255922\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5498747, shape=(), dtype=float32)\n",
      "beginning  361 : x\n",
      "beginning  362 : x\n",
      "beginning  363 : x\n",
      "beginning  364 : x\n",
      "beginning  365 : x\n",
      "beginning  366 : x\n",
      "beginning  367 : x\n",
      "beginning  368 : x\n",
      "beginning  369 : x\n",
      "beginning  370 : x\n",
      "beginning  371 : x\n",
      "beginning  372 : x\n",
      "beginning  373 : x\n",
      "beginning  374 : x\n",
      "beginning  375 : x\n",
      "beginning  376 : x\n",
      "beginning  377 : x\n",
      "beginning  378 : x\n",
      "beginning  379 : x\n",
      "beginning  380 : x\n",
      "loss:  0.5236992\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.548734, shape=(), dtype=float32)\n",
      "beginning  381 : x\n",
      "beginning  382 : x\n",
      "beginning  383 : x\n",
      "beginning  384 : x\n",
      "beginning  385 : x\n",
      "beginning  386 : x\n",
      "beginning  387 : x\n",
      "beginning  388 : x\n",
      "beginning  389 : x\n",
      "beginning  390 : x\n",
      "beginning  391 : x\n",
      "beginning  392 : x\n",
      "beginning  393 : x\n",
      "beginning  394 : x\n",
      "beginning  395 : x\n",
      "beginning  396 : x\n",
      "beginning  397 : x\n",
      "beginning  398 : x\n",
      "beginning  399 : x\n",
      "beginning  400 : x\n",
      "loss:  0.52184635\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5476196, shape=(), dtype=float32)\n",
      "beginning  401 : x\n",
      "beginning  402 : x\n",
      "beginning  403 : x\n",
      "beginning  404 : x\n",
      "beginning  405 : x\n",
      "beginning  406 : x\n",
      "beginning  407 : x\n",
      "beginning  408 : x\n",
      "beginning  409 : x\n",
      "beginning  410 : x\n",
      "beginning  411 : x\n",
      "beginning  412 : x\n",
      "beginning  413 : x\n",
      "beginning  414 : x\n",
      "beginning  415 : x\n",
      "beginning  416 : x\n",
      "beginning  417 : x\n",
      "beginning  418 : x\n",
      "beginning  419 : x\n",
      "beginning  420 : x\n",
      "loss:  0.52002656\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5464968, shape=(), dtype=float32)\n",
      "beginning  421 : x\n",
      "beginning  422 : x\n",
      "beginning  423 : x\n",
      "beginning  424 : x\n",
      "beginning  425 : x\n",
      "beginning  426 : x\n",
      "beginning  427 : x\n",
      "beginning  428 : x\n",
      "beginning  429 : x\n",
      "beginning  430 : x\n",
      "beginning  431 : x\n",
      "beginning  432 : x\n",
      "beginning  433 : x\n",
      "beginning  434 : x\n",
      "beginning  435 : x\n",
      "beginning  436 : x\n",
      "beginning  437 : x\n",
      "beginning  438 : x\n",
      "beginning  439 : x\n",
      "beginning  440 : x\n",
      "loss:  0.5182423\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5453702, shape=(), dtype=float32)\n",
      "beginning  441 : x\n",
      "beginning  442 : x\n",
      "beginning  443 : x\n",
      "beginning  444 : x\n",
      "beginning  445 : x\n",
      "beginning  446 : x\n",
      "beginning  447 : x\n",
      "beginning  448 : x\n",
      "beginning  449 : x\n",
      "beginning  450 : x\n",
      "beginning  451 : x\n",
      "beginning  452 : x\n",
      "beginning  453 : x\n",
      "beginning  454 : x\n",
      "beginning  455 : x\n",
      "beginning  456 : x\n",
      "beginning  457 : x\n",
      "beginning  458 : x\n",
      "beginning  459 : x\n",
      "beginning  460 : x\n",
      "loss:  0.51648754\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.5442732, shape=(), dtype=float32)\n",
      "beginning  461 : x\n",
      "beginning  462 : x\n",
      "beginning  463 : x\n",
      "beginning  464 : x\n",
      "beginning  465 : x\n",
      "beginning  466 : x\n",
      "beginning  467 : x\n",
      "beginning  468 : x\n",
      "beginning  469 : x\n",
      "beginning  470 : x\n",
      "beginning  471 : x\n",
      "beginning  472 : x\n",
      "beginning  473 : x\n",
      "beginning  474 : x\n",
      "beginning  475 : x\n",
      "beginning  476 : x\n",
      "beginning  477 : x\n",
      "beginning  478 : x\n",
      "beginning  479 : x\n",
      "beginning  480 : x\n",
      "loss:  0.5147628\n",
      "validating...x\n",
      "Validation loss:  tf.Tensor(0.54317725, shape=(), dtype=float32)\n",
      "beginning  481 : x\n",
      "beginning  482 : x\n",
      "beginning  483 : x\n",
      "beginning  484 : x\n",
      "beginning  485 : x\n",
      "beginning  486 : x\n",
      "beginning  487 : x\n",
      "beginning  488 : x\n",
      "beginning  489 : x\n",
      "beginning  490 : x\n",
      "beginning  491 : x\n",
      "beginning  492 : x\n",
      "beginning  493 : x\n",
      "beginning  494 : x\n",
      "beginning  495 : x\n",
      "beginning  496 : x\n",
      "beginning  497 : x\n",
      "beginning  498 : x\n",
      "beginning  499 : x\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nout, y, loss, val_loss, out_model = main(train=Fase,dimensions=dimensionss,act=\"standard\")\\n#out, y, loss, out_model = main(train=False, model= out_model, filenames = [\\'./train_x.npz\\', \\'./train_y.npz\\', \\'train_x\\', \\'train_y\\'])\\n\\nfilename = out_model.specs\\nrecall_arr, precision_arr = analysis(out, y)\\nsave_res = np.savez(\"./Results/\"+filename+\".npz\", recall_arr = recall_arr, precision_arr = precision_arr)\\nplt.plot(recall_arr, precision_arr)\\nplt.xlabel(\\'recall\\')\\nplt.ylabel(\\'precision\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cell 4\n",
    "#training cell\n",
    "#default = [[4096,2048,1024,512,200],[400,200,84]]\n",
    "#fig,ax = plt.subplots(1,1)\n",
    "dimensionss = [[4096,1024,512,200],[200,84]]\n",
    "train_test, train_y, loss_arr, val_loss_arr, out_model = main(train=True,dimensions=dimensionss,act=\"standard\",valid_filenames=['./test_x.npz', './test_y.npz', 'test_x', 'test_y'])\n",
    "#cell 5\n",
    "#testing model demo\n",
    "#out_model = ComplexFCNetwork([[4096,2048,200],[84]])\n",
    "#out_model.load_weights('./weights/EigthData.ckpt')\n",
    "\n",
    "plt.plot(loss_arr, label='train')\n",
    "plt.plot(val_loss_arr, label='val')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "out, y, loss, val_loss, out_model = main(train=Fase,dimensions=dimensionss,act=\"standard\")\n",
    "#out, y, loss, out_model = main(train=False, model= out_model, filenames = ['./train_x.npz', './train_y.npz', 'train_x', 'train_y'])\n",
    "\n",
    "filename = out_model.specs\n",
    "recall_arr, precision_arr = analysis(out, y)\n",
    "save_res = np.savez(\"./Results/\"+filename+\".npz\", recall_arr = recall_arr, precision_arr = precision_arr)\n",
    "plt.plot(recall_arr, precision_arr)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis2(y_hat, y):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y, y_hat)\n",
    "    return precision,recall,thresholds\n",
    "    \n",
    "def AP(y_hat, y):\n",
    "    ap = metrics.average_precision_score(y, y_hat)\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...(1, 4096, 2000)\n",
      "train_y shape:  (2000, 84)\n",
      "(1, 4096, 2000)\n",
      "y batched:  (1, 2000, 84)\n",
      "6780.0\n",
      "Done\n",
      "y_hat:  [4.1613894e-13 1.3108438e-07 4.9710857e-06 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "test y:  [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision:  0.058265440856015566\n"
     ]
    }
   ],
   "source": [
    "#out, y, loss, val_loss, out_model = main(model=out_model, train=False,dimensions=dimensionss,act=\"standard\",train_filenames=['./test_x.npz', './test_y.npz', 'test_x', 'test_y'])\n",
    "#out, y, loss, out_model = main(train=False, model= out_model, filenames = ['./train_x.npz', './train_y.npz', 'train_x', 'train_y'])\n",
    "test_filenames=['./test_x.npz', './test_y.npz', 'test_x', 'test_y']\n",
    "#test_filenames=['./train_x.npz', './train_y.npz', 'train_x', 'train_y']\n",
    "test_x, test_y = load_data(test_filenames)\n",
    "y_hat = test(out_model, test_x, test_y).numpy().flatten()\n",
    "test_y = test_y[0].numpy().flatten()\n",
    "print(\"y_hat: \", y_hat)\n",
    "print(\"test y: \", test_y)\n",
    "precision_arr, recall_arr, thresholds = analysis2(y_hat, test_y)\n",
    "ap = AP(y_hat, test_y)\n",
    "plt.plot(recall_arr, precision_arr)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.show()\n",
    "print(\"Average Precision: \", ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-59a5babaff38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mones_histo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mones_histo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "ones = np.where(test_y.numpy().flatten() >= 1)[0]\n",
    "ones_histo = []\n",
    "for one in ones:\n",
    "    ones_histo.append(y_hat[one])\n",
    "    print(one)\n",
    "#print(histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained model\n",
    "test_net = ComplexFCNetwork([4096,2048,200,84])\n",
    "test_net.load_weights('./weights/EigthData.ckpt')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load testing data\n",
    "load_x = np.load('./test_x.npz')\n",
    "load_y = np.load('./test_y.npz')\n",
    "#load_x = np.load('./train_x.npz')\n",
    "#load_y = np.load('./train_y.npz')\n",
    "\n",
    "#print(Y_complex[0])\n",
    "test_x = load_x['test_x'].T\n",
    "test_y = load_y['test_y']\n",
    "#test_x = load_x['train_x'].T\n",
    "#test_y = load_y['train_y']\n",
    "print(\"tesst_x\", test_x.shape)\n",
    "#test_x = test_x[:,:,0:100]\n",
    "#test_y = test_y[0:100]\n",
    "\n",
    "y_value = 1\n",
    "print(train_y[0].shape, test_y.shape)\n",
    "test_x = np.concatenate((train_x, test_x), axis=2)[:,:,0:100]\n",
    "test_y = np.concatenate((train_y[0], test_y),axis=0)[:,0:100]\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "num_batch = 1\n",
    "samples_per_batch = test_x.shape[2]//num_batch\n",
    "test_x_fft = np.zeros((num_batch, test_x.shape[1], samples_per_batch)).astype('complex64')\n",
    "print(\"test_x_fft shape\", test_x_fft.shape)\n",
    "test_y_batched = np.zeros((num_batch, samples_per_batch,test_y.shape[1]))\n",
    "print(\"y batched: \", test_y_batched.shape)\n",
    "cur_batch = 0\n",
    "cur_sample = 0\n",
    "for col in range(test_x_fft.shape[2]):\n",
    "    test_x_fft[cur_batch,:,cur_sample] = np.fft.fft(test_x[cur_batch,:,col])\n",
    "    test_y_batched[cur_batch,cur_sample,:] = test_y[col,:]\n",
    "    if cur_sample >= samples_per_batch:\n",
    "        cur_batch += 1\n",
    "        cur_sample = 0\n",
    "    if cur_batch >= num_batch:\n",
    "        break\n",
    "    cur_sample += 1\n",
    "print(test_x_fft[0,:,0])\n",
    "test_x = tf.convert_to_tensor(test_x_fft,dtype='complex64')\n",
    "#train_y = tf.cast(tf.complex(train_y,train_y),dtype='complex64')\n",
    "print(np.sum(test_y.flatten()))\n",
    "test_y = tf.cast(test_y_batched,dtype='float32')\n",
    "#print(train_x)\n",
    "#train_x = tf.reshape(train_x, [1,train_x.shape[0], train_x.shape[1]])\n",
    "#train_y = tf.reshape(train_y, [1, train_y.shape[1], train_y.shape[0]])\n",
    "\n",
    "print(test_y.shape)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_y[0][1])\n",
    "print(test_y[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing loop\n",
    "def test():\n",
    "    #test = ComplexFCNetwork([4096,4096,2048,2048,1024,1024,512,264,128,84])\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    epochs = 1\n",
    "    eta = 1\n",
    "    loss_arr = []\n",
    "    truths = []\n",
    "    falses = []\n",
    "    test_out = [0]*test_x.shape[2]\n",
    "    for epoch in range(epochs):\n",
    "        print(\"begining \", epoch, \": \", end = '')\n",
    "        for batch in range(test_x.shape[0]):\n",
    "            for sample in range(test_x.shape[2]):\n",
    "                x = tf.reshape(test_x[batch,:,sample],[test_x[batch,:,:].shape[0],1])\n",
    "                y = tf.reshape(test_y[batch,sample,:],[test_y[batch,sample,:].shape[0],1])\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_hat = tf.transpose(model(x))\n",
    "                    if epoch+1 == epochs: #saves the final output of our network\n",
    "                        test_out[sample] = y_hat\n",
    "            print(\"x\", end='')\n",
    "        print(\"\")\n",
    "\n",
    "    \n",
    "    print(\"Done\")\n",
    "    return test_out, loss_arr\n",
    "train_test_test, loss_arr = test()\n",
    "\n",
    "#np.savez(\"./models/singlepointloss.npz\", loss_arr=loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision algorithms\n",
    "\n",
    "def convert_to_binary(y_hat,thresh):\n",
    "    return np.where(y_hat > thresh, y_value, 0)\n",
    "\n",
    "def metrics(y_hat, truth):\n",
    "    #print(\"y_hat\", y_hat)\n",
    "    #print(\"truth\", truth)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for feature in range(len(y_hat)):\n",
    "        for sample in range(len(y_hat[feature])):\n",
    "            if y_hat[feature][sample] == 0 and truth[feature][sample] == 0:\n",
    "                tn += 1\n",
    "            elif y_hat[feature][sample] == 0 and truth[feature][sample] == y_value:\n",
    "                fn += 1\n",
    "            elif y_hat[feature][sample] == y_value and truth[feature][sample] == 0:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "list_to_numpy = [train_test_test[0].numpy()]\n",
    "i = 1\n",
    "while ( i < len(train_test_test)):\n",
    "    list_to_numpy.append(train_test_test[i].numpy())\n",
    "    i += 1\n",
    "\n",
    "numpy_to_tensor = (np.reshape(np.asarray(list_to_numpy),(len(list_to_numpy),list_to_numpy[0].shape[0])))\n",
    "\n",
    "train_test_2 = tf.convert_to_tensor(numpy_to_tensor)\n",
    "\n",
    "print(train_test_2.shape)\n",
    "#train_test_2 = tf.convert_to_tensor(np.concatenate((train_test[0].numpy(),train_test[1].numpy()),axis=1))\n",
    "#print(train_test_2.shape)\n",
    "cur_thresh = 0\n",
    "recall_arr = []\n",
    "precision_arr = []\n",
    "while(cur_thresh < 1):\n",
    "    bin_y_hat = convert_to_binary(train_test_2,cur_thresh).astype(np.float32)\n",
    "    #print(bin_y_hat.shape)\n",
    "    compare = test_y.numpy().reshape((test_y.shape[1],test_y.shape[2]))\n",
    "    #print(compare.shape)\n",
    "    tp, fp, fn, tn = metrics(bin_y_hat,compare)\n",
    "\n",
    "    print(tp, fp, fn, tn)\n",
    "    accuracy = (tp + tn) / (len(bin_y_hat)*len(bin_y_hat[0]))\n",
    "    if (tp + fp) == 0:\n",
    "        break\n",
    "    if (tp + fp) == 0 or (tp + fn ) == 0:\n",
    "        cur_thresh += 0.001\n",
    "        continue\n",
    "    precision = (tp) / (tp + fp)\n",
    "    recall = (tp) / (tp + fn)\n",
    "    recall_arr.append(recall)\n",
    "    precision_arr.append(precision)\n",
    "    cur_thresh += 0.001\n",
    "\n",
    "#print(\"Accuracy: \", accuracy, \"|| Precision: \", precision, \"|| Recall: \", recall)\n",
    "print(precision_arr, recall_arr)\n",
    "plt.plot(recall_arr, precision_arr)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "y_real = [[1.]]\n",
    "y_imag = [[0.]]\n",
    "#train_x = tf.cast(tf.complex(x_real,x_imag),dtype=complex_dtype)\n",
    "train_y = tf.cast(tf.complex(y_real,y_imag),dtype=complex_dtype)\n",
    "\n",
    "y_2_real = [[10.]]\n",
    "y_2_imag = [[10.]]\n",
    "train_y_2 = tf.cast(tf.complex(y_2_real, y_2_imag),dtype=complex_dtype)\n",
    "\n",
    "mse_loss_fn(train_y,train_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input MSE: \", ((train_x[0,:,0].numpy()-train_x[0,:,1].numpy())**2).mean(axis=0))\n",
    "print(\"MSE: \", ((train_test[0].numpy()-train_test[1].numpy())**2).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model test\n",
    "loaded = ComplexFCNetwork([4096,2048,200,84])\n",
    "loaded.load_weights('./weights/QuarterData.ckpt')\n",
    "\n",
    "print(loaded(tf.reshape(train_x[0,:,0],[train_x[0,:,:].shape[0],1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for optimizer test code (done)\n",
    "#DO NOT RUN\n",
    "#optimizer testing: run network 300 times and take average loss\n",
    "overall_loss = []\n",
    "i = 0\n",
    "while ( i < 300):\n",
    "    print(\"run \", i, \"-----------------------------\")\n",
    "    test_out, train_y, loss_arr, model = main(train=True)\n",
    "    overall_loss.append(loss_arr)\n",
    "    to_save_x = np.savez(\"./no_cadam_loss_matrix_200.npz\", overall_loss = overall_loss)\n",
    "    i += 1\n",
    "\n",
    "to_save_x = np.savez(\"./no_cadam_loss_matrix_200.npz\", overall_loss = overall_loss)\n",
    "\n",
    "#DO NOT RUN\n",
    "#plotting average losses\n",
    "\n",
    "no_cadam = np.load('no_cadam_loss_matrix_200.npz')\n",
    "cadam = np.load('cadam_loss_matrix_200.npz')\n",
    "\n",
    "#DO NOT RUN\n",
    "#optimizer works :D\n",
    "no_cadam_arr = no_cadam['overall_loss']\n",
    "cadam_arr = cadam['overall_loss']\n",
    "\n",
    "no_cadam_arr = np.average(no_cadam_arr, axis=0)\n",
    "cadam_arr = np.average(cadam_arr, axis=0)\n",
    "\n",
    "print(no_cadam_arr)\n",
    "print(cadam_arr)\n",
    "plt.plot(no_cadam_arr, label = 'no optim')\n",
    "plt.plot(cadam_arr, label= 'optim')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cells for data manipulation\n",
    "#DO NOT RUN NORMALLY\n",
    "#dummy data\n",
    "\n",
    "train_x = np.random.random((100,20))\n",
    "train_x = train_x.T\n",
    "train_x = tf.convert_to_tensor(np.reshape(train_x + train_x*1j,(1,train_x.shape[0],train_x.shape[1])),dtype='complex64')\n",
    "\n",
    "train_y = np.random.random((100,10)) + np.random.random((100,10))*1j\n",
    "\n",
    "train_y = tf.convert_to_tensor(np.reshape(train_y,(1,train_y.shape[0],train_y.shape[1])),dtype='complex64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 1\n",
    "#DONT RUN\n",
    "#cell to load in data\n",
    "data = np.load('./validation.npz')\n",
    "X = data['XValid']\n",
    "Y = data['YValid']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 4\n",
    "#DONT RUN\n",
    "#training and testing set creation\n",
    "num_samples = 10000\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "\n",
    "train_x = X[0:num_samples]\n",
    "train_y = Y[0:num_samples]\n",
    "\n",
    "to_save_x = np.savez(\"./train_x.npz\", train_x = train_x)\n",
    "to_save_y = np.savez(\"./train_y.npz\", train_y = train_y)\n",
    "\n",
    "num_test = num_samples//5\n",
    "test_x = X[num_samples:num_samples+num_test]\n",
    "test_y = Y[num_samples:num_samples+num_test]\n",
    "\n",
    "to_save_x_test = np.savez(\"./test_x.npz\", test_x = test_x)\n",
    "to_save_y_test = np.savez(\"./test_y.npz\", test_y = test_y)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN NORMALLY\n",
    "#tests for activation func from reichart\n",
    "\n",
    "def reich_act(weight,x):\n",
    "    print(\"-------------------\")\n",
    "    product = np.matmul(weight,x.T)\n",
    "    out_arr = []\n",
    "    for i in range(weight.shape[1]):\n",
    "        out_arr.append(weight[0,i]*x[0,i])\n",
    "    ret_mag = abs(product)\n",
    "    ret_phase = cmath.phase(product)\n",
    "    print(\"phase 1: \", cmath.phase(out_arr[0]))\n",
    "    print(\"phase 2: \", cmath.phase(out_arr[1]))\n",
    "    phase_scaling = (1 - (abs(cmath.phase(out_arr[0])) - abs(cmath.phase(out_arr[1])))/(2*math.pi))\n",
    "    print(\"phase_scale: \", phase_scaling)\n",
    "    #print(\"out mag: \", ret_mag)\n",
    "    print('ret_mag b4 scale: ', ret_mag)\n",
    "    ret_mag = ret_mag*phase_scaling\n",
    "    print('ret_mag: ', ret_mag)\n",
    "    return ret_mag\n",
    "\n",
    "\n",
    "x = np.asarray([[cmath.rect(5, -1*math.pi), cmath.rect(5, -1*math.pi)]])\n",
    "w = np.asarray([[1, 1]])\n",
    "cur_phase_diff = 0\n",
    "mag_graph = []\n",
    "while(cur_phase_diff < 2 * math.pi):\n",
    "    print(cur_phase_diff)\n",
    "    x[0,1] = cmath.rect(abs(x[0,0]),cmath.phase(x[0,0])+cur_phase_diff)\n",
    "    print(\"??: \", cmath.phase(x[0,0]+cur_phase_diff))\n",
    "    cur_phase_diff += 0.2\n",
    "    out = reich_act(w,x)\n",
    "    mag_graph.append(out[0,0])\n",
    "\n",
    "print(mag_graph)\n",
    "plt.plot(mag_graph)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
