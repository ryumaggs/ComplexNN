{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "###### cell 0\n",
    "#cell for imports and system variable set ups\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.python.framework import ops\n",
    "#import random\n",
    "import numpy as np\n",
    "from scipy.fft import fft, ifft\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#cell 1:\n",
    "#data loader\n",
    "#note: scipy fft requires the array to be in M x N format, where M = samples, and N = features\n",
    "\n",
    "def load_data(file_var_names):\n",
    "    print(\"Loading data...\", end='')\n",
    "    load_x = np.load(file_var_names[0])\n",
    "    load_y = np.load(file_var_names[1])\n",
    "\n",
    "    #print(Y_complex[0])\n",
    "    train_x = load_x[file_var_names[2]].T\n",
    "    train_y = load_y[file_var_names[3]]\n",
    "\n",
    "    y_value = 1\n",
    "\n",
    "    #ones = [i for i, x in enumerate(train_y) if x == 1]\n",
    "    #zeros = [i for i, x in enumerate(train_y) if x == 0]\n",
    "    #print(ones)\n",
    "    #print(train_x.shape)\n",
    "    #plt.plot(X[0])\n",
    "    #plt.show()\n",
    "\n",
    "    print(train_x.shape)\n",
    "    print(\"train_y shape: \", train_y.shape)\n",
    "    num_batch = 1\n",
    "    samples_per_batch = train_x.shape[2]//num_batch\n",
    "    train_x_fft = np.zeros((num_batch, train_x.shape[1], samples_per_batch)).astype('complex64')\n",
    "    train_y_batched = np.zeros((num_batch, samples_per_batch,train_y.shape[1]))\n",
    "    print(train_x_fft.shape)\n",
    "    print(\"y batched: \", train_y_batched.shape)\n",
    "    cur_batch = 0\n",
    "    cur_sample = 0\n",
    "    for col in range(train_x_fft.shape[2]):\n",
    "        train_x_fft[cur_batch,:,cur_sample] = np.fft.fft(train_x[0,:,col])\n",
    "        train_y_batched[cur_batch,cur_sample,:] = train_y[col,:]\n",
    "        if cur_sample >= samples_per_batch:\n",
    "            cur_batch += 1\n",
    "            cur_sample = 0\n",
    "        if cur_batch >= num_batch:\n",
    "            break\n",
    "        cur_sample += 1\n",
    "\n",
    "    train_x = tf.convert_to_tensor(train_x_fft,dtype='complex64')\n",
    "    print(np.sum(train_y.flatten()))\n",
    "    train_y = tf.cast(train_y_batched,dtype='float32')\n",
    "    print(\"Done\")\n",
    "    return train_x, train_y\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "###### cell 2:\n",
    "#helper functions\n",
    "\n",
    "complex_dtype = 'complex64'\n",
    "def cReLU(x):\n",
    "    #print(x)\n",
    "    ret_real = tf.math.real(x)\n",
    "    ret_imag = tf.math.imag(x)\n",
    "    ret_real = tf.nn.relu(ret_real)\n",
    "    ret_imag = tf.nn.relu(ret_imag)\n",
    "    return tf.complex(ret_real,ret_imag)\n",
    "np_cReLU = np.vectorize(cReLU)\n",
    "\n",
    "def P2C(radii, angles):\n",
    "    x = tf.multiply(radii, tf.math.cos(angles))\n",
    "    y = tf.multiply(radii, tf.math.sin(angles))\n",
    "    return tf.cast(tf.complex(x,y),dtype='complex64')\n",
    "\n",
    "y = tf.constant([2.0, 8.0])\n",
    "x = tf.constant([2.0, 8.0])\n",
    "\n",
    "#print(P2C(y,x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class ComplexDenseLayer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,input_dim,num_outputs,activation):\n",
    "        super(ComplexDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        real = np.random.normal(loc=0.0, scale=(2/input_dim), size=(input_dim,self.num_outputs))\n",
    "        imag = np.random.normal(loc=0.0, scale=(2/input_dim), size=(input_dim,self.num_outputs))\n",
    "        complex_mat = tf.cast(tf.complex(real,imag),complex_dtype)\n",
    "        self.w = tf.Variable(complex_mat, dtype=complex_dtype,trainable=True)\n",
    "        bias_real = np.random.rand(self.num_outputs,1)\n",
    "        bias_imag = np.random.rand(self.num_outputs,1)\n",
    "        bias_complex = tf.cast(tf.complex(bias_real, bias_imag),complex_dtype)\n",
    "        self.b = tf.Variable(bias_complex,dtype=complex_dtype,trainable=True)\n",
    "        self.activation=activation\n",
    "\n",
    "    def call(self,inputs):\n",
    "        batch_b = tf.repeat(self.b,inputs.shape[1],1)\n",
    "        out = tf.matmul(tf.transpose(self.w),inputs)+batch_b\n",
    "        if self.activation==\"phase\":\n",
    "            out = tf.convert_to_tensor(P2C(tf.math.abs(out)*0.5,tf.math.angle(out)),dtype='complex64')\n",
    "            out += tf.convert_to_tensor(P2C(tf.matmul(tf.transpose(tf.math.abs(self.w)),tf.math.abs(inputs)*0.5),tf.math.angle(out)),dtype='complex64')\n",
    "            out += batch_b\n",
    "        #print(type(out))\n",
    "        return out\n",
    "\n",
    "class Complex1DConvLayer(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, stride, padding, kernel_size):\n",
    "        output_shape = (input_dim-kernel_size + 2*padding)/stride\n",
    "    def call(self,inputs):\n",
    "        batch_b = tf.repeat(self.b, inputs.shape[1],1)\n",
    "        return tf.matmul(tf.transpose(self.w), inputs)+batch_b\n",
    "\n",
    "class Complex1DMaxPool(keras.layers.Layer):\n",
    "    def __init__(self,input_dim,stride,padding,kernel_size):\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_shape = (input_dim-kernel_size + 2*padding)/stride\n",
    "    def call(self,inputs):\n",
    "        #assumes data is given as features x samples\n",
    "        out = tf.convert_to_tensor(np.zeros((self.out_shape, inputs.shape[1])) + np.zeros((self.out_shape, inputs.shape[1]))*1j, dtype='complex64')\n",
    "        for sample in range(inputs.shape[1]):\n",
    "            out[:,sample] = tf.convert_to_tensor(maxMagnitude(inputs[:,sample].numpy()), dtype='complex64')\n",
    "        return out\n",
    "        \n",
    "    def MaxMagnitude(sample):\n",
    "        #assumes that sample is given as a numpy array\n",
    "        max_pooled = np.zeros((self.out_shape,1)) + np.zeros((self.out_shape,1))*1j\n",
    "        sample_mag = abs(sample)\n",
    "        out_index = 0\n",
    "        kernel_start = 0\n",
    "        while(out_index < max_pooled.shape[0]):\n",
    "            max_pooled[out_index] = sample[kernel_start + np.argmax(sample_mag[kernel_start:kernel_start+self.kernel_size])]\n",
    "            out_index += 1\n",
    "            kernel_start += self.stride\n",
    "        return max_pooled\n",
    "\n",
    "class ComplexFCNetwork(keras.Model):\n",
    "    def __init__(self, dimensions, activation, name=\"ComplexValueFC\", **kwargs):\n",
    "        super(ComplexFCNetwork, self).__init__(name=name,**kwargs)\n",
    "        self.specs = str(dimensions)\n",
    "        complex_dimensions = dimensions[0]\n",
    "        real_dimensions = dimensions[1]\n",
    "        self.orig_shape = complex_dimensions[0]\n",
    "        self.layerz = []\n",
    "        self.m = []\n",
    "        self.v = []\n",
    "        self.num_complex_layers = len(complex_dimensions) - 1\n",
    "        self.num_real_layers = len(real_dimensions)\n",
    "        #complex layers\n",
    "        for index in range(len(complex_dimensions)-1):\n",
    "            self.layerz.append(ComplexDenseLayer(complex_dimensions[index],complex_dimensions[index+1],activation))\n",
    "            #weight momentum\n",
    "            self.m.append(np.zeros((complex_dimensions[index],complex_dimensions[index+1]))+np.zeros((complex_dimensions[index],complex_dimensions[index+1]))*1j)\n",
    "            self.v.append(np.zeros((complex_dimensions[index],complex_dimensions[index+1]))+np.zeros((complex_dimensions[index],complex_dimensions[index+1]))*1j)\n",
    "            #bias momentum\n",
    "            self.m.append(np.zeros((complex_dimensions[index+1],1)))\n",
    "            self.v.append(np.zeros((complex_dimensions[index+1],1)))\n",
    "        #complex-real transition\n",
    "        act = 'sigmoid'\n",
    "        if len(real_dimensions) > 1:\n",
    "            act = 'relu'\n",
    "            \n",
    "        self.layerz.append(tf.keras.layers.Dense(real_dimensions[0],activation=act))\n",
    "        self.m.append(np.zeros((complex_dimensions[-1]*2, real_dimensions[0])))\n",
    "        self.v.append(np.zeros((complex_dimensions[-1]*2, real_dimensions[0])))\n",
    "        #bias momentum\n",
    "        self.m.append(np.zeros((real_dimensions[0])))\n",
    "        self.v.append(np.zeros((real_dimensions[0])))\n",
    "        if len(real_dimensions) > 1:\n",
    "            real_index = 1\n",
    "            while(real_index < len(real_dimensions)):\n",
    "                #print(\"real: \", real_index)\n",
    "                if (real_index +1) >= len(real_dimensions):\n",
    "                    act = 'sigmoid'\n",
    "                else:\n",
    "                    act = 'relu'\n",
    "                #print(\"ading layer: \", real_dimensions[real_index])\n",
    "                self.layerz.append(tf.keras.layers.Dense(real_dimensions[real_index],activation=act))\n",
    "                self.m.append(np.zeros((real_dimensions[real_index-1], real_dimensions[real_index])))\n",
    "                self.v.append(np.zeros((real_dimensions[real_index-1],real_dimensions[real_index])))\n",
    "                #bias momentum\n",
    "                self.m.append(np.zeros((real_dimensions[real_index])))\n",
    "                self.v.append(np.zeros((real_dimensions[real_index])))\n",
    "                real_index += 1\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #print(\"self.layerz: \", self.layerz)\n",
    "        ret = inputs\n",
    "        index = 0\n",
    "        while index < self.num_complex_layers:\n",
    "            #print(\"layer: \", index, \" out: \", ret)\n",
    "            ret = cReLU((self.layerz[index])(ret))\n",
    "            index += 1\n",
    "        #ret_real = tf.math.real(ret)\n",
    "        #ret_imag = tf.math.imag(ret)\n",
    "        #ret = tf.transpose(tf.concat([ret_real,ret_imag],0))\n",
    "        ret_r = tf.math.abs(ret)\n",
    "        ret_phi = tf.math.angle(ret)\n",
    "        ret = tf.concat([ret_r,ret_phi],0)\n",
    "        \n",
    "        ret = tf.transpose(ret)\n",
    "        #print(\"ret shape: \", ret.shape)\n",
    "        #print(\"aa. \", ret.shape)\n",
    "        #print(\"c layers \", self.num_complex_layers)\n",
    "        #print(\"num_real: \", self.num_real_layers)\n",
    "        #print(\"index: \", index)\n",
    "        #print(len(self.layerz))\n",
    "        #print(self.layerz)\n",
    "        #print(ret.shape)\n",
    "        \n",
    "        while index < (self.num_complex_layers + self.num_real_layers):\n",
    "            #print(\"passing through dense\")\n",
    "            ret = (self.layerz[index])(ret)\n",
    "            #print(\"dense shapes: \", ret.shape)\n",
    "            index += 1\n",
    "        return ret\n",
    "\n",
    "def cadam(lr,grad,m,v,t):\n",
    "    #print(\"m: \", m.shape)\n",
    "    #print(\"v: \", v.shape)\n",
    "    #print(\"grad: \", grad.shape)\n",
    "    b1 = 0.9\n",
    "    b2 = 0.999\n",
    "    epsilon = .0001\n",
    "    m = b1 * m + (1 - b1) * (grad)\n",
    "    v = b2 * v + (1 - b2) * (np.power(grad,2))\n",
    "    m_hat = m/(1-np.power(b1,t+1))\n",
    "    v_hat = v/(1-np.power(b2,t+1))\n",
    "    return lr*m_hat/(np.sqrt(v_hat)+epsilon)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#cell 3:\n",
    "#main training/testing function\n",
    "def main(train=True, dimensions=[[4096,2048,1024,512,200],[400,200,84]],model = None, filenames=['./train_x.npz', './train_y.npz', 'train_x', 'train_y']):\n",
    "    train_x, train_y = load_data(filenames)\n",
    "    #test = ComplexFCNetwork([4096,4096,2048,2048,1024,1024,512,264,128,84])\n",
    "    if model == None:\n",
    "        print(\"made new model!\")\n",
    "        model = ComplexFCNetwork([[4096,2048,1024,512,200],[400,200,84]],activation=\"standard\")\n",
    "        #model = ComplexFCNetwork([[20,512,200,100,120,100,80,40,20],[10]])\n",
    "\n",
    "    mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    learning_rate = 0.006\n",
    "    #checkpoint_path = \"./models/single_data_model.ckpt\"\n",
    "    #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    epochs = 300\n",
    "    if train == False:\n",
    "        epochs = 1\n",
    "    eta = 0.99\n",
    "    loss_arr = []\n",
    "    truths = []\n",
    "    falses = []\n",
    "    test_out = []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"beginning \", epoch, \": \", end = '')\n",
    "        for batch in range(train_x.shape[0]):\n",
    "            x = train_x[batch,:,:]\n",
    "            y = train_y[batch,:,:]\n",
    "            #print(\"x: \", x.shape)\n",
    "            #print(\"y: \", y.shape)\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_hat = model(x)\n",
    "                #print(\"self.v: \", len(model.v))\n",
    "                #print(\"self.m: \", len(model.m))\n",
    "                #print(\"trainable count: \", len(model.trainable_weights))\n",
    "                #print(\"y_hat: \", y_hat.shape)\n",
    "                loss = mse_loss_fn(y, tf.math.real(y_hat))\n",
    "                if epoch+1 == epochs: #saves the final output of our network\n",
    "                    test_out = y_hat\n",
    "            #print(\"Tape:\", tape)\n",
    "            if train == True:\n",
    "                #print(model.trainable_weights)\n",
    "                grads = tape.gradient(loss, model.trainable_weights)\n",
    "                #print(\"grads: \", grads)\n",
    "                #print(grads)\n",
    "                for i in range(len(model.trainable_weights)):\n",
    "                    #print(\"I: \", i)\n",
    "                    cadam_grad = cadam(learning_rate,grads[i],model.m[i], model.v[i], epoch+1)\n",
    "                    tf.compat.v1.assign(model.trainable_weights[i],tf.math.subtract(model.trainable_weights[i]*eta,cadam_grad))\n",
    "                    #tf.compat.v1.assign(model.trainable_weights[i],tf.math.subtract(model.trainable_weights[i]*eta,learning_rate*grads[i]))\n",
    "            print(\"x\", end='')\n",
    "        print(\"\")\n",
    "        if train == True and ((epoch) %20 == 0 or epoch == epochs):\n",
    "            print(\"loss: \", loss.numpy())\n",
    "            loss_arr.append(loss.numpy())\n",
    "            #print(\"saving model...\", end='')\n",
    "            model.save_weights('./weights/depthTest.ckpt')\n",
    "            #print(\"Done\",end='\\n')\n",
    "    \n",
    "    print(\"Done\")\n",
    "    return test_out, train_y, loss_arr, model\n",
    "\n",
    "#np.savez(\"./models/singlepointloss.npz\", loss_arr=loss_arr)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 6\n",
    "#analysis cell\n",
    "\n",
    "def convert_to_binary(y_hat,thresh, y_value = 1):\n",
    "    return np.where(y_hat > thresh, y_value, 0)\n",
    "\n",
    "def metrics(y_hat, truth, y_value = 1):\n",
    "    #print(\"y_hat\", y_hat)\n",
    "    #print(\"truth\", truth)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for feature in range(len(y_hat)):\n",
    "        for sample in range(len(y_hat[feature])):\n",
    "            if y_hat[feature][sample] == 0 and truth[feature][sample] == 0:\n",
    "                tn += 1\n",
    "            elif y_hat[feature][sample] == 0 and truth[feature][sample] == y_value:\n",
    "                fn += 1\n",
    "            elif y_hat[feature][sample] == y_value and truth[feature][sample] == 0:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "    return tp, fp, fn, tn\n",
    "def analysis(train_test, train_y, y_value = 1):\n",
    "    list_to_numpy = [train_test[0].numpy()]\n",
    "    i = 1\n",
    "    while ( i < len(train_test)):\n",
    "        list_to_numpy.append(train_test[i].numpy())\n",
    "        i += 1\n",
    "\n",
    "    numpy_to_tensor = (np.reshape(np.asarray(list_to_numpy),(1,len(list_to_numpy),list_to_numpy[0].shape[0])))\n",
    "\n",
    "    train_test_2 = tf.convert_to_tensor(numpy_to_tensor)\n",
    "\n",
    "    print(train_test_2.shape)\n",
    "    #train_test_2 = tf.convert_to_tensor(np.concatenate((train_test[0].numpy(),train_test[1].numpy()),axis=1))\n",
    "    #print(train_test_2.shape)\n",
    "    recall_arr = []\n",
    "    precision_arr = []\n",
    "    print(train_y.shape)\n",
    "    batch = 0\n",
    "    AP = 0\n",
    "    while batch < train_y.shape[0]:\n",
    "        cur_thresh = 0\n",
    "        while(cur_thresh < 1):\n",
    "            #print(cur_thresh)\n",
    "            bin_y_hat = convert_to_binary(train_test_2,cur_thresh).astype(np.float32)\n",
    "            #print(bin_y_hat.shape)\n",
    "            compare = train_y.numpy()\n",
    "            #print(compare.shape)\n",
    "            #print(bin_y_hat[batch].shape)\n",
    "            tp, fp, fn, tn = metrics(bin_y_hat[batch],compare[batch])\n",
    "\n",
    "            print(\"tp: \", tp, \"fp: \", fp, \"fn: \", fn, \"tn: \", tn)\n",
    "            \n",
    "            accuracy = (tp + tn) / (len(bin_y_hat)*len(bin_y_hat[0]))\n",
    "            if (tp + fp) == 0:\n",
    "                cur_thresh += 0.02\n",
    "                break\n",
    "            if (tp + fn) == 0:\n",
    "                cur_thresh += 0.02\n",
    "                continue\n",
    "            precision = (tp) / (tp + fp)\n",
    "            recall = (tp) / (tp + fn)\n",
    "            print(\"recall: \", recall, \" precision: \", precision)\n",
    "            if cur_thresh != 0:\n",
    "                AP += -1*(recall-recall_arr[-1])*precision\n",
    "            recall_arr.append(recall)\n",
    "            precision_arr.append(precision)\n",
    "            cur_thresh += 0.02\n",
    "        batch += 1\n",
    "\n",
    "    #print(\"Accuracy: \", accuracy, \"|| Precision: \", precision, \"|| Recall: \", recall)\n",
    "    #print(precision_arr, recall_arr)\n",
    "    print(\"Average Precision (AP):\", AP)\n",
    "    return recall_arr, precision_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...(1, 4096, 20000)\n",
      "train_y shape:  (20000, 84)\n",
      "(1, 4096, 20000)\n",
      "y batched:  (1, 20000, 84)\n",
      "67533.0\n",
      "Done\n",
      "made new model!\n",
      "beginning  0 : x\n",
      "loss:  0.2709129\n",
      "beginning  1 : x\n",
      "beginning  2 : x\n",
      "beginning  3 : "
     ]
    }
   ],
   "source": [
    "#cell 4\n",
    "#training cell\n",
    "#default = [[4096,2048,1024,512,200],[400,200,84]]\n",
    "dimensionss = [[4096,2048,1024,512,200],[400,200,84]]\n",
    "train_test, train_y, loss_arr, out_model = main(train=True,dimensions=dimensionss)\n",
    "#cell 5\n",
    "#testing model demo\n",
    "#out_model = ComplexFCNetwork([[4096,2048,200],[84]])\n",
    "#out_model.load_weights('./weights/EigthData.ckpt')\n",
    "\n",
    "out, y, loss, out_model = main(train=False, model= out_model, dimensions=dimensionss,filenames = ['./test_x.npz', './test_y.npz', 'test_x', 'test_y'])\n",
    "#out, y, loss, out_model = main(train=False, model= out_model, filenames = ['./train_x.npz', './train_y.npz', 'train_x', 'train_y'])\n",
    "\n",
    "filename = out_model.specs\n",
    "recall_arr, precision_arr = analysis(out, y)\n",
    "save_res = np.savez(\"./Results/\"+filename+\".npz\", recall_arr = recall_arr, precision_arr = precision_arr)\n",
    "plt.plot(recall_arr, precision_arr)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained model\n",
    "test_net = ComplexFCNetwork([4096,2048,200,84])\n",
    "test_net.load_weights('./weights/EigthData.ckpt')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load testing data\n",
    "load_x = np.load('./test_x.npz')\n",
    "load_y = np.load('./test_y.npz')\n",
    "#load_x = np.load('./train_x.npz')\n",
    "#load_y = np.load('./train_y.npz')\n",
    "\n",
    "#print(Y_complex[0])\n",
    "test_x = load_x['test_x'].T\n",
    "test_y = load_y['test_y']\n",
    "#test_x = load_x['train_x'].T\n",
    "#test_y = load_y['train_y']\n",
    "print(\"tesst_x\", test_x.shape)\n",
    "#test_x = test_x[:,:,0:100]\n",
    "#test_y = test_y[0:100]\n",
    "\n",
    "y_value = 1\n",
    "print(train_y[0].shape, test_y.shape)\n",
    "test_x = np.concatenate((train_x, test_x), axis=2)[:,:,0:100]\n",
    "test_y = np.concatenate((train_y[0], test_y),axis=0)[:,0:100]\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "num_batch = 1\n",
    "samples_per_batch = test_x.shape[2]//num_batch\n",
    "test_x_fft = np.zeros((num_batch, test_x.shape[1], samples_per_batch)).astype('complex64')\n",
    "print(\"test_x_fft shape\", test_x_fft.shape)\n",
    "test_y_batched = np.zeros((num_batch, samples_per_batch,test_y.shape[1]))\n",
    "print(\"y batched: \", test_y_batched.shape)\n",
    "cur_batch = 0\n",
    "cur_sample = 0\n",
    "for col in range(test_x_fft.shape[2]):\n",
    "    test_x_fft[cur_batch,:,cur_sample] = np.fft.fft(test_x[cur_batch,:,col])\n",
    "    test_y_batched[cur_batch,cur_sample,:] = test_y[col,:]\n",
    "    if cur_sample >= samples_per_batch:\n",
    "        cur_batch += 1\n",
    "        cur_sample = 0\n",
    "    if cur_batch >= num_batch:\n",
    "        break\n",
    "    cur_sample += 1\n",
    "print(test_x_fft[0,:,0])\n",
    "test_x = tf.convert_to_tensor(test_x_fft,dtype='complex64')\n",
    "#train_y = tf.cast(tf.complex(train_y,train_y),dtype='complex64')\n",
    "print(np.sum(test_y.flatten()))\n",
    "test_y = tf.cast(test_y_batched,dtype='float32')\n",
    "#print(train_x)\n",
    "#train_x = tf.reshape(train_x, [1,train_x.shape[0], train_x.shape[1]])\n",
    "#train_y = tf.reshape(train_y, [1, train_y.shape[1], train_y.shape[0]])\n",
    "\n",
    "print(test_y.shape)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_y[0][1])\n",
    "print(test_y[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing loop\n",
    "def test():\n",
    "    #test = ComplexFCNetwork([4096,4096,2048,2048,1024,1024,512,264,128,84])\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    epochs = 1\n",
    "    eta = 1\n",
    "    loss_arr = []\n",
    "    truths = []\n",
    "    falses = []\n",
    "    test_out = [0]*test_x.shape[2]\n",
    "    for epoch in range(epochs):\n",
    "        print(\"begining \", epoch, \": \", end = '')\n",
    "        for batch in range(test_x.shape[0]):\n",
    "            for sample in range(test_x.shape[2]):\n",
    "                x = tf.reshape(test_x[batch,:,sample],[test_x[batch,:,:].shape[0],1])\n",
    "                y = tf.reshape(test_y[batch,sample,:],[test_y[batch,sample,:].shape[0],1])\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_hat = tf.transpose(model(x))\n",
    "                    if epoch+1 == epochs: #saves the final output of our network\n",
    "                        test_out[sample] = y_hat\n",
    "            print(\"x\", end='')\n",
    "        print(\"\")\n",
    "\n",
    "    \n",
    "    print(\"Done\")\n",
    "    return test_out, loss_arr\n",
    "train_test_test, loss_arr = test()\n",
    "\n",
    "#np.savez(\"./models/singlepointloss.npz\", loss_arr=loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision algorithms\n",
    "\n",
    "def convert_to_binary(y_hat,thresh):\n",
    "    return np.where(y_hat > thresh, y_value, 0)\n",
    "\n",
    "def metrics(y_hat, truth):\n",
    "    #print(\"y_hat\", y_hat)\n",
    "    #print(\"truth\", truth)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for feature in range(len(y_hat)):\n",
    "        for sample in range(len(y_hat[feature])):\n",
    "            if y_hat[feature][sample] == 0 and truth[feature][sample] == 0:\n",
    "                tn += 1\n",
    "            elif y_hat[feature][sample] == 0 and truth[feature][sample] == y_value:\n",
    "                fn += 1\n",
    "            elif y_hat[feature][sample] == y_value and truth[feature][sample] == 0:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "list_to_numpy = [train_test_test[0].numpy()]\n",
    "i = 1\n",
    "while ( i < len(train_test_test)):\n",
    "    list_to_numpy.append(train_test_test[i].numpy())\n",
    "    i += 1\n",
    "\n",
    "numpy_to_tensor = (np.reshape(np.asarray(list_to_numpy),(len(list_to_numpy),list_to_numpy[0].shape[0])))\n",
    "\n",
    "train_test_2 = tf.convert_to_tensor(numpy_to_tensor)\n",
    "\n",
    "print(train_test_2.shape)\n",
    "#train_test_2 = tf.convert_to_tensor(np.concatenate((train_test[0].numpy(),train_test[1].numpy()),axis=1))\n",
    "#print(train_test_2.shape)\n",
    "cur_thresh = 0\n",
    "recall_arr = []\n",
    "precision_arr = []\n",
    "while(cur_thresh < 1):\n",
    "    bin_y_hat = convert_to_binary(train_test_2,cur_thresh).astype(np.float32)\n",
    "    #print(bin_y_hat.shape)\n",
    "    compare = test_y.numpy().reshape((test_y.shape[1],test_y.shape[2]))\n",
    "    #print(compare.shape)\n",
    "    tp, fp, fn, tn = metrics(bin_y_hat,compare)\n",
    "\n",
    "    print(tp, fp, fn, tn)\n",
    "    accuracy = (tp + tn) / (len(bin_y_hat)*len(bin_y_hat[0]))\n",
    "    if (tp + fp) == 0:\n",
    "        break\n",
    "    if (tp + fp) == 0 or (tp + fn ) == 0:\n",
    "        cur_thresh += 0.001\n",
    "        continue\n",
    "    precision = (tp) / (tp + fp)\n",
    "    recall = (tp) / (tp + fn)\n",
    "    recall_arr.append(recall)\n",
    "    precision_arr.append(precision)\n",
    "    cur_thresh += 0.001\n",
    "\n",
    "#print(\"Accuracy: \", accuracy, \"|| Precision: \", precision, \"|| Recall: \", recall)\n",
    "print(precision_arr, recall_arr)\n",
    "plt.plot(recall_arr, precision_arr)\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "y_real = [[1.]]\n",
    "y_imag = [[0.]]\n",
    "#train_x = tf.cast(tf.complex(x_real,x_imag),dtype=complex_dtype)\n",
    "train_y = tf.cast(tf.complex(y_real,y_imag),dtype=complex_dtype)\n",
    "\n",
    "y_2_real = [[10.]]\n",
    "y_2_imag = [[10.]]\n",
    "train_y_2 = tf.cast(tf.complex(y_2_real, y_2_imag),dtype=complex_dtype)\n",
    "\n",
    "mse_loss_fn(train_y,train_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input MSE: \", ((train_x[0,:,0].numpy()-train_x[0,:,1].numpy())**2).mean(axis=0))\n",
    "print(\"MSE: \", ((train_test[0].numpy()-train_test[1].numpy())**2).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model test\n",
    "loaded = ComplexFCNetwork([4096,2048,200,84])\n",
    "loaded.load_weights('./weights/QuarterData.ckpt')\n",
    "\n",
    "print(loaded(tf.reshape(train_x[0,:,0],[train_x[0,:,:].shape[0],1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for optimizer test code (done)\n",
    "#DO NOT RUN\n",
    "#optimizer testing: run network 300 times and take average loss\n",
    "overall_loss = []\n",
    "i = 0\n",
    "while ( i < 300):\n",
    "    print(\"run \", i, \"-----------------------------\")\n",
    "    test_out, train_y, loss_arr, model = main(train=True)\n",
    "    overall_loss.append(loss_arr)\n",
    "    to_save_x = np.savez(\"./no_cadam_loss_matrix_200.npz\", overall_loss = overall_loss)\n",
    "    i += 1\n",
    "\n",
    "to_save_x = np.savez(\"./no_cadam_loss_matrix_200.npz\", overall_loss = overall_loss)\n",
    "\n",
    "#DO NOT RUN\n",
    "#plotting average losses\n",
    "\n",
    "no_cadam = np.load('no_cadam_loss_matrix_200.npz')\n",
    "cadam = np.load('cadam_loss_matrix_200.npz')\n",
    "\n",
    "#DO NOT RUN\n",
    "#optimizer works :D\n",
    "no_cadam_arr = no_cadam['overall_loss']\n",
    "cadam_arr = cadam['overall_loss']\n",
    "\n",
    "no_cadam_arr = np.average(no_cadam_arr, axis=0)\n",
    "cadam_arr = np.average(cadam_arr, axis=0)\n",
    "\n",
    "print(no_cadam_arr)\n",
    "print(cadam_arr)\n",
    "plt.plot(no_cadam_arr, label = 'no optim')\n",
    "plt.plot(cadam_arr, label= 'optim')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cells for data manipulation\n",
    "#DO NOT RUN NORMALLY\n",
    "#dummy data\n",
    "\n",
    "train_x = np.random.random((100,20))\n",
    "train_x = train_x.T\n",
    "train_x = tf.convert_to_tensor(np.reshape(train_x + train_x*1j,(1,train_x.shape[0],train_x.shape[1])),dtype='complex64')\n",
    "\n",
    "train_y = np.random.random((100,10)) + np.random.random((100,10))*1j\n",
    "\n",
    "train_y = tf.convert_to_tensor(np.reshape(train_y,(1,train_y.shape[0],train_y.shape[1])),dtype='complex64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 1\n",
    "#DONT RUN\n",
    "#cell to load in data\n",
    "data = np.load('./validation.npz')\n",
    "X = data['XValid']\n",
    "Y = data['YValid']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#cell 4\n",
    "#DONT RUN\n",
    "#training and testing set creation\n",
    "num_samples = 20000\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "#X = X[indices]\n",
    "#Y = Y[indices]\n",
    "\n",
    "train_x = X[0:num_samples]\n",
    "train_y = Y[0:num_samples]\n",
    "to_save_x = np.savez(\"./train_x.npz\", train_x = train_x)\n",
    "to_save_y = np.savez(\"./train_y.npz\", train_y = train_y)\n",
    "\n",
    "num_test = num_samples//5\n",
    "test_x = X[num_samples:num_samples+num_test]\n",
    "test_y = Y[num_samples:num_samples+num_test]\n",
    "\n",
    "to_save_x_test = np.savez(\"./test_x.npz\", test_x = test_x)\n",
    "to_save_y_test = np.savez(\"./test_y.npz\", test_y = test_y)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN NORMALLY\n",
    "#tests for activation func from reichart\n",
    "\n",
    "def reich_act(weight,x):\n",
    "    print(\"-------------------\")\n",
    "    product = np.matmul(weight,x.T)\n",
    "    out_arr = []\n",
    "    for i in range(weight.shape[1]):\n",
    "        out_arr.append(weight[0,i]*x[0,i])\n",
    "    ret_mag = abs(product)\n",
    "    ret_phase = cmath.phase(product)\n",
    "    print(\"phase 1: \", cmath.phase(out_arr[0]))\n",
    "    print(\"phase 2: \", cmath.phase(out_arr[1]))\n",
    "    phase_scaling = (1 - (abs(cmath.phase(out_arr[0])) - abs(cmath.phase(out_arr[1])))/(2*math.pi))\n",
    "    print(\"phase_scale: \", phase_scaling)\n",
    "    #print(\"out mag: \", ret_mag)\n",
    "    print('ret_mag b4 scale: ', ret_mag)\n",
    "    ret_mag = ret_mag*phase_scaling\n",
    "    print('ret_mag: ', ret_mag)\n",
    "    return ret_mag\n",
    "\n",
    "\n",
    "x = np.asarray([[cmath.rect(5, -1*math.pi), cmath.rect(5, -1*math.pi)]])\n",
    "w = np.asarray([[1, 1]])\n",
    "cur_phase_diff = 0\n",
    "mag_graph = []\n",
    "while(cur_phase_diff < 2 * math.pi):\n",
    "    print(cur_phase_diff)\n",
    "    x[0,1] = cmath.rect(abs(x[0,0]),cmath.phase(x[0,0])+cur_phase_diff)\n",
    "    print(\"??: \", cmath.phase(x[0,0]+cur_phase_diff))\n",
    "    cur_phase_diff += 0.2\n",
    "    out = reich_act(w,x)\n",
    "    mag_graph.append(out[0,0])\n",
    "\n",
    "print(mag_graph)\n",
    "plt.plot(mag_graph)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
