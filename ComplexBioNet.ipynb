{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "###### cell 0\n",
    "#cell for imports and system variable set ups\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "#sys.path.append('.'+os.sep+\"src\")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "#from tensorflow.keras import backend\n",
    "from tensorflow.python.framework import ops\n",
    "#import random\n",
    "import numpy as np\n",
    "from scipy.fft import fft, ifft\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath\n",
    "from sklearn import metrics\n",
    "from src.complex_net.nn.layers.dense import ComplexDense\n",
    "from src.complex_net.nn.layers.activations import ComplexReLU as cReLU\n",
    "\n",
    "from src.complex_net.nn.models.fc import *\n",
    "\n",
    "from src.complex_net.nn.models.biofc import *\n",
    "\n",
    "from src.complex_net.nn.models.cnn import *\n",
    "\n",
    "from src.complex_net.nn.optimizers.cadam import *\n",
    "\n",
    "from src.complex_net.data.musicnet import *\n",
    "\n",
    "from src.complex_net.nn.initializers.complex_glorot_uniform import ComplexGlorotUniform\n",
    "\n",
    "from src.real_net.nn.models.fc_real import *\n",
    "\n",
    "from src.real_net.data.musicnet_real import *\n",
    "\n",
    "from dataset import *\n",
    "\n",
    "import random\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset= tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = dset.load_data()\n",
    "\n",
    "all_images = np.concatenate((train_images,test_images),0)\n",
    "all_labels = np.concatenate((train_labels,test_labels),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset= tf.keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = dset.load_data()\n",
    "\n",
    "all_images = np.concatenate((train_images,test_images),0)\n",
    "all_labels = np.concatenate((train_labels,test_labels),0)\n",
    "\n",
    "all_images = np.squeeze(np.asarray((tf.image.rgb_to_grayscale(all_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(all_images.shape)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe88092d710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(all_images[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_images\n",
    "y_test = test_labels\n",
    "X_test = X_test.reshape(1,X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
    "X_test = (X_test/256.0).astype('float32')\n",
    "y_temp = np.zeros((y_test.size, int(y_test.max())+1))\n",
    "y_temp[np.arange(y_test.size),y_test] = 1\n",
    "y_test = y_temp.reshape(1, y_temp.shape[0], y_temp.shape[1])\n",
    "print(\"x_test: \", X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = np.load(\"./low_dim_scales/low_dim_scale_1.npz\")\n",
    "dset = dset['x']\n",
    "labels = np.load(\"./low_dim_scales/low_dim_labels.npz\")\n",
    "labels = labels['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#537482\n",
    "split = 10062\n",
    "shuffler = np.random.permutation(len(dset))\n",
    "dset = dset[shuffler]\n",
    "labels = np.reshape(labels[shuffler],(labels[shuffler].size,))\n",
    "train_images = dset[:-split]\n",
    "test_images = dset[-split:]\n",
    "train_labels = labels[:-split]\n",
    "test_labels = labels[-split:]\n",
    "\n",
    "X_train = train_images\n",
    "y_train = train_labels\n",
    "#shuffler = np.random.permutation(len(X_train))\n",
    "#X_train = X_train[shuffler]\n",
    "#y_train = y_train[shuffler]\n",
    "batches = train_images.shape[0]//50\n",
    "if X_train.ndim == 3:\n",
    "    X_train = X_train.reshape(batches,X_train.shape[0]//batches,X_train.shape[1]*X_train.shape[2])\n",
    "elif X_train.ndim == 2:\n",
    "    X_train = X_train.reshape(batches,X_train.shape[0]//batches,X_train.shape[1])\n",
    "X_train = (X_train/256.0).astype('float32')\n",
    "y_temp = np.zeros((y_train.size, int(y_train.max())+1))\n",
    "y_temp[np.arange(y_train.size),y_train] = 1\n",
    "y_train = y_temp.reshape(batches,y_temp.shape[0]//batches,y_temp.shape[1])\n",
    "print(\"x_train: \", X_train.shape)\n",
    "print(y_train.shape)\n",
    "        \n",
    "X_test = test_images\n",
    "y_test = test_labels\n",
    "X_test = X_test.reshape(1,X_test.shape[0],X_test.shape[1])\n",
    "X_test = (X_test/256.0).astype('float32')\n",
    "y_temp = np.zeros((y_test.size, int(y_test.max())+1))\n",
    "y_temp[np.arange(y_test.size),y_test] = 1\n",
    "y_test = y_temp.reshape(1, y_temp.shape[0], y_temp.shape[1])\n",
    "print(\"x_test: \", X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#penalize difference in phase\n",
    "class customDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_units: int, **kwargs) -> None:\n",
    "        super(customDense, self).__init__(**kwargs)\n",
    "        self.num_units: int = int(num_units)\n",
    "\n",
    "        self.W: tf.Variable = None\n",
    "        self.b: tf.Variable = None\n",
    "        self.p: tf.Variable = None\n",
    "\n",
    "    # lazy parameter allocation...only allocate upon the first call to self.call(...)\n",
    "    def build(self, input_shape: List[int]) -> None:\n",
    "        #print(\"aisjd: \", input_shape)\n",
    "        #print(\"asidj: \", self.num_units)\n",
    "        W_init: GlorotUniform = ComplexGlorotUniform(input_shape[-1])\n",
    "        b_init: GlorotUniform = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "        self.W = self.add_weight(name='w',\n",
    "                                 shape=(input_shape[-1], self.num_units,),\n",
    "                                 initializer=W_init,\n",
    "                                 dtype=tf.complex64,\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(1,self.num_units,),\n",
    "                                 initializer=b_init,\n",
    "                                 dtype=tf.float32,\n",
    "                                 trainable=True)\n",
    "        \n",
    "\n",
    "    def P2C(self,radii, angles):\n",
    "        x = tf.multiply(radii, tf.math.cos(angles))\n",
    "        y = tf.multiply(radii, tf.math.sin(angles))\n",
    "        return tf.cast(tf.complex(x,y),dtype='complex64')\n",
    "\n",
    "    def call(self, X: tf.Tensor, **kwargs) -> tf.Tensor:\n",
    "        #print(\"X: \", X)\n",
    "        #print(\"w: \", self.W)\n",
    "        out = 0.5*tf.matmul(X, tf.math.abs(self.W)) + 0.5*tf.math.abs(tf.matmul(tf.cast(tf.complex(X, tf.zeros(X.shape)),dtype='complex64'),self.W))\n",
    "        return out + self.b\n",
    "\n",
    "    def get_config(self) -> Dict:\n",
    "        config: Dict[str, ...] = super(ComplexDense, self).get_config()\n",
    "        config.update({\"num_units\": self.num_units})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#penalize diff in phase and reward same phase:\n",
    "\n",
    "class customDense2(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_units: int, activity_regularizer=None,**kwargs) -> None:\n",
    "        super(customDense2, self).__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
    "        self.num_units: int = int(num_units)\n",
    "\n",
    "        self.W: tf.Variable = None\n",
    "        self.b: tf.Variable = None\n",
    "        self.p: tf.Variable = None\n",
    "\n",
    "    # lazy parameter allocation...only allocate upon the first call to self.call(...)\n",
    "    def build(self, input_shape: List[int]) -> None:\n",
    "        #print(\"aisjd: \", input_shape)\n",
    "        #print(\"asidj: \", self.num_units)\n",
    "        W_init: GlorotUniform = ComplexGlorotUniform(input_shape[-1])\n",
    "        b_init: GlorotUniform = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "        self.W = self.add_weight(name='w',\n",
    "                                 shape=(input_shape[-1], self.num_units,),\n",
    "                                 initializer=W_init,\n",
    "                                 dtype=tf.complex64,\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(1,self.num_units,),\n",
    "                                 initializer=b_init,\n",
    "                                 dtype=tf.float32,\n",
    "                                 trainable=True)\n",
    "        \n",
    "\n",
    "    def P2C(self,radii, angles):\n",
    "        x = tf.multiply(radii, tf.math.cos(angles))\n",
    "        y = tf.multiply(radii, tf.math.sin(angles))\n",
    "        return tf.cast(tf.complex(x,y),dtype='complex64')\n",
    "\n",
    "    def call(self, X: tf.Tensor, **kwargs) -> tf.Tensor:\n",
    "        #print(\"X: \", X)\n",
    "        #print(\"w: \", self.W)\n",
    "        term_1 = tf.matmul(X, tf.math.abs(self.W))\n",
    "        term_2 = tf.math.abs(tf.matmul(tf.cast(tf.complex(X, tf.zeros(X.shape)),dtype='complex64'),self.W))\n",
    "        term_3 = (1-((term_1-term_2)/term_1))*term_1\n",
    "        out = 0.5*term_1 + 0.5*term_2 + 0.5*term_3\n",
    "        return out + self.b\n",
    "\n",
    "    def get_config(self) -> Dict:\n",
    "        config: Dict[str, ...] = super(ComplexDense, self).get_config()\n",
    "        config.update({\"num_units\": self.num_units})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealFC(tf.keras.Model):\n",
    "    def __init__(self, decoder_dims: List[int], **kwargs) -> None:\n",
    "        super(RealFC, self).__init__(**kwargs)\n",
    "        self.decoder_dims: List[int] = list(decoder_dims)\n",
    "        self.num_layers = len(self.decoder_dims)\n",
    "        if len(self.decoder_dims) == 0:\n",
    "            raise ValueError(\"ERROR: real_decoder_dims must have at least 1 element\")\n",
    "\n",
    "        self.decoder_layers = list()\n",
    "\n",
    "        for num_units in self.decoder_dims[:-1]:\n",
    "            if len(self.decoder_dims) == 1:\n",
    "                self.decoder_layers.append(customDense2(num_units,activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "                self.decoder_layers.append(tf.keras.layers.Activation('sigmoid'))\n",
    "                #print('used sigmoid')\n",
    "            else:\n",
    "                self.decoder_layers.append(customDense2(num_units,activity_regularizer=tf.keras.regularizers.L2(0.)))\n",
    "                self.decoder_layers.append(tf.keras.layers.ReLU(threshold=0.))\n",
    "                self.decoder_layers.append(tf.keras.layers.BatchNormalization())\n",
    "                #print(\"used relu\")\n",
    "        self.decoder_layers.append(customDense2(self.decoder_dims[-1]))\n",
    "        self.decoder_layers.append(tf.keras.layers.Softmax())\n",
    "\n",
    "    def call(self, X: tf.Tensor) -> tf.Tensor:\n",
    "        #print(X)\n",
    "        for layer in self.decoder_layers:\n",
    "            #print(X)\n",
    "            #print(layer)\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexConvNet(tf.keras.Model):\n",
    "    def __init__(self, conv_dims, decoder_dims, **kwargs) -> None:\n",
    "        '''\n",
    "        input:\n",
    "            conv_dims: list[tuples], where each tuple = (num_filter, filter_shape, stride, padding)\n",
    "                num_filter: int\n",
    "                filter_shape: int\n",
    "                stride: tuple\n",
    "                padding = str, see TF documentation on Conv2D\n",
    "            \n",
    "        '''\n",
    "        super(ConvNet, self).__init__(**kwargs)\n",
    "        self.decoder_dims: List[int] = list(decoder_dims)\n",
    "        self.conv_dims: List[int] = list(conv_dims)\n",
    "        self.num_layers = len(self.decoder_dims)\n",
    "        \n",
    "        if len(self.decoder_dims) == 0:\n",
    "            raise ValueError(\"ERROR: real_decoder_dims must have at least 1 element\")\n",
    "\n",
    "        self.decoder_layers = list()\n",
    "        self.conv_layers = list()\n",
    "        \n",
    "        for i in range(len(self.conv_dims)):\n",
    "            self.conv_layers.append(tf.keras.layers.Conv2D(conv_dims[i][0], conv_dims[i][1], strides=conv_dims[i][2], \n",
    "                                                           padding=conv_dims[i][3], activation='relu',trainable=True))\n",
    "            self.conv_layers.append(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "            \n",
    "        for num_units in self.decoder_dims[:-1]:\n",
    "            if len(self.decoder_dims) == 1:\n",
    "                self.decoder_layers.append(customDense(num_units,activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "                self.decoder_layers.append(tf.keras.layers.Activation('sigmoid'))\n",
    "                #print('used sigmoid')\n",
    "            else:\n",
    "                self.decoder_layers.append(customDense(num_units,activity_regularizer=tf.keras.regularizers.L2(0.)))\n",
    "                self.decoder_layers.append(tf.keras.layers.ReLU(threshold=0.))\n",
    "                self.decoder_layers.append(tf.keras.layers.BatchNormalization())\n",
    "                #print(\"used relu\")\n",
    "        self.decoder_layers.append(customDense2(self.decoder_dims[-1]))\n",
    "        self.decoder_layers.append(tf.keras.layers.Softmax())\n",
    "        \n",
    "        print(\"conv layers: \", len(self.conv_layers), \" || decoder layers: \", len(self.decoder_layers))\n",
    "        \n",
    "        print(self.conv_layers)\n",
    "        print(self.decoder_layers)\n",
    "\n",
    "    def call(self, X: tf.Tensor) -> tf.Tensor:\n",
    "        #ACCIDENTALLY REMOVED FLATTEN LINE. POTENTIALLY DON'T NEED TO RE-ADD\n",
    "        for layer in self.conv_layers:\n",
    "            X = layer(X)\n",
    "        for layer in self.decoder_layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(tf.keras.Model):\n",
    "    def __init__(self, conv_dims, decoder_dims, **kwargs) -> None:\n",
    "        '''\n",
    "        input:\n",
    "            conv_dims: list[tuples], where each tuple = (num_filter, filter_shape, stride, padding)\n",
    "                num_filter: int\n",
    "                filter_shape: int\n",
    "                stride: tuple\n",
    "                padding = str, see TF documentation on Conv2D\n",
    "            \n",
    "        '''\n",
    "        super(ConvNet, self).__init__(**kwargs)\n",
    "        self.decoder_dims: List[int] = list(decoder_dims)\n",
    "        self.conv_dims: List[int] = list(conv_dims)\n",
    "        self.num_layers = len(self.decoder_dims)\n",
    "        \n",
    "        if len(self.decoder_dims) == 0:\n",
    "            raise ValueError(\"ERROR: real_decoder_dims must have at least 1 element\")\n",
    "\n",
    "        self.decoder_layers = list()\n",
    "        self.conv_layers = list()\n",
    "        \n",
    "        for i in range(len(self.conv_dims)):\n",
    "            self.conv_layers.append(tf.keras.layers.Conv2D(conv_dims[i][0], conv_dims[i][1], strides=conv_dims[i][2], \n",
    "                                                           padding=conv_dims[i][3], activation='relu',trainable=True))\n",
    "            self.conv_layers.append(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        self.conv_layers.append(tf.keras.layers.Flatten())\n",
    "        for num_units in self.decoder_dims[:-1]:\n",
    "            self.decoder_layers.append(tf.keras.layers.Dense(num_units,activity_regularizer=tf.keras.regularizers.L2(0.)))\n",
    "            self.decoder_layers.append(tf.keras.layers.ReLU(threshold=0.))\n",
    "            self.decoder_layers.append(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        self.decoder_layers.append(tf.keras.layers.Dense(self.decoder_dims[-1],activity_regularizer=tf.keras.regularizers.L2(0.)))\n",
    "        self.decoder_layers.append(tf.keras.layers.Softmax())\n",
    "        \n",
    "        print(\"conv layers: \", len(self.conv_layers), \" || decoder layers: \", len(self.decoder_layers))\n",
    "        \n",
    "        print(\"conv layers: \", self.conv_layers)\n",
    "        print(\"\")\n",
    "        print(\"dense layers: \", self.decoder_layers)\n",
    "\n",
    "    def call(self, X: tf.Tensor) -> tf.Tensor:\n",
    "        for layer in self.conv_layers:\n",
    "            X = layer(X)\n",
    "        for layer in self.decoder_layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dims = [(32,(3,3),1,'valid'),(64,(3,3),1,'valid'),(64,(3,3),1,'valid')]\n",
    "dims = [20,10]\n",
    "dims_str = \"20,10_mnist_dense2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture output\n",
    "#adjustable parameters\n",
    "real = 1\n",
    "complexx = 0\n",
    "conv = 1\n",
    "graph = 0\n",
    "limit = 100\n",
    "save = 0\n",
    "\n",
    "#non-adjustable parameters\n",
    "count = 1\n",
    "out = 0\n",
    "loss = 0\n",
    "\n",
    "#variable setup\n",
    "real_loss = []\n",
    "complex_loss = []\n",
    "running_real_conf_matrix = []\n",
    "running_complex_conf_matrix = []\n",
    "if save == 1:\n",
    "    f_name = \"dim:\"+dims_str+\"_\"+str(limit)+\"_runs_accuracy.txt\"\n",
    "    f_name_matrix = \"dim:\"+dims_str+\"_\"+str(limit)+\"_runs_confusion_matrix.txt\"\n",
    "    diff_conf_matrix = np.zeros((10,10),dtype='float')\n",
    "    f_path_matrix = \"./Results/\"+f_name_matrix\n",
    "\n",
    "while(count < limit+1):\n",
    "    best_real_conf_matrix = []\n",
    "    best_complex_conf_matrix = []\n",
    "    real_max = 0\n",
    "    complex_max = 0\n",
    "    if save == 1:\n",
    "        f_path = \"./Results/\"+f_name\n",
    "        hs = open(f_path,\"a\")\n",
    "        hs.write(\"0,0\\n\")\n",
    "        hs.close()\n",
    "        mat_f = open(f_path_matrix,\"a\")\n",
    "        mat_f.write(\"0\\n\")\n",
    "        mat_f.close()\n",
    "    \n",
    "    epochs = 60\n",
    "    \n",
    "    if complexx == 1:\n",
    "        complex_model = RealFC(dims)\n",
    "        if conv == 1:\n",
    "            complex_model = ConvNet(conv_dims,dims)\n",
    "        complex_optimizer = Cadam()\n",
    "        #complex_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        complex_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    if real == 1:\n",
    "        real_model = ConvNet(conv_dims,dims)\n",
    "        real_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        real_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    shuffler = np.random.permutation(len(all_images))\n",
    "    print(type(all_images))\n",
    "    print(shuffler)\n",
    "    print(all_images.shape)\n",
    "    all_images = all_images[shuffler]\n",
    "    all_labels = all_labels[shuffler]\n",
    "    \n",
    "    X_test = all_images[-10000:]\n",
    "    y_test = all_labels[-10000:]\n",
    "    \n",
    "    if conv == 0:\n",
    "        X_test = X_test.reshape(1,X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
    "        X_test = (X_test/256.0).astype('float32')\n",
    "        y_temp = np.zeros((y_test.size, int(y_test.max())+1))\n",
    "        y_temp[np.arange(y_test.size),y_test] = 1\n",
    "        y_test = y_temp.reshape(1, y_temp.shape[0], y_temp.shape[1])\n",
    "    if conv == 1:\n",
    "        X_test = X_test.reshape(1,X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "        X_test = (X_test/256.0).astype('float32')\n",
    "        y_temp = np.zeros((y_test.size, int(y_test.max())+1))\n",
    "        y_temp[np.arange(y_test.size),y_test] = 1\n",
    "        y_test = y_temp.reshape(1, y_temp.shape[0], y_temp.shape[1])\n",
    "        \n",
    "    print(\"X_test shape: \", X_test.shape)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        real_conf_matrix = []\n",
    "        complex_conf_matrix = []\n",
    "        \n",
    "        X_train = all_images[:10000]\n",
    "        y_train = all_labels[:10000]\n",
    "        shuffler = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[shuffler]\n",
    "        y_train = y_train[shuffler]\n",
    "        batches = train_images.shape[0]//50\n",
    "        if X_train.ndim == 3 and conv == 0:\n",
    "            X_train = X_train.reshape(batches,X_train.shape[0]//batches,X_train.shape[1]*X_train.shape[2])\n",
    "        elif X_train.ndim == 2 and conv == 0:\n",
    "            X_train = X_train.reshape(batches,X_train.shape[0]//batches,X_train.shape[1])\n",
    "        \n",
    "        if X_train.ndim == 3 and conv == 1:\n",
    "            X_train = X_train.reshape(batches,X_train.shape[0]//batches,X_train.shape[1],X_train.shape[2],1)\n",
    "        elif X_train.ndim == 2 and conv == 1:\n",
    "            X_train = X_train.reshape(batches,X_train.shape[0]//batches,X_train.shape[1],1)\n",
    "            \n",
    "        print(\"X_train shape: \", X_train.shape)\n",
    "        X_train = (X_train/256.0).astype('float32')\n",
    "        y_temp = np.zeros((y_train.size, int(y_train.max())+1))\n",
    "        y_temp[np.arange(y_train.size),y_train] = 1\n",
    "        #print(\"y temp: \", y_temp.shape)\n",
    "        y_train = y_temp.reshape(batches,y_temp.shape[0]//batches,y_temp.shape[1])\n",
    "        #print(\"after manip: \", y_train.shape)\n",
    "        #print(X_test.shape)\n",
    "        #validate:\n",
    "        print(\"----------epoch: \", epoch,\"------------------\")\n",
    "        if real == 1:\n",
    "            real_v_out = real_model(X_test[0])\n",
    "            real_v_loss = real_loss_fn(y_test[0], real_v_out)\n",
    "            real_v_out_bin = real_v_out.numpy()\n",
    "            real_v_out_bin = (real_v_out_bin == real_v_out_bin.max(axis=1, keepdims=1)).astype(float)\n",
    "            #real_v_ap = metrics.average_precision_score(y_test[0],real_v_out.numpy())\n",
    "            real_v_acc = metrics.accuracy_score(y_test[0],real_v_out_bin)\n",
    "            truth_int = np.asarray([np.where(r==1)[0][0] for r in y_test[0]])\n",
    "            pred_int = np.asarray([np.where(r==1)[0][0] for r in real_v_out_bin])\n",
    "            real_conf_matrix = metrics.confusion_matrix(truth_int, pred_int)\n",
    "            #print(\"conf: \", real_conf_matrix)\n",
    "            #print(\"truth: \", truth_int)\n",
    "            print(\"real loss: \", real_v_loss)\n",
    "            print(\"real acc:\", real_v_acc)\n",
    "            \n",
    "        if complexx == 1:\n",
    "            complex_v_out = complex_model(X_test[0])\n",
    "            complex_v_out_bin = complex_v_out.numpy()\n",
    "            complex_v_out_bin = (complex_v_out_bin == complex_v_out_bin.max(axis=1, keepdims=1)).astype(float)\n",
    "            complex_v_loss = complex_loss_fn(y_test[0], complex_v_out)\n",
    "            #complex_v_ap = metrics.average_precision_score(y_test[0],complex_v_out.numpy())\n",
    "            complex_v_acc = metrics.accuracy_score(y_test[0],complex_v_out_bin)\n",
    "            truth_int = np.asarray([np.where(r==1)[0][0] for r in y_test[0]])\n",
    "            pred_int = np.asarray([np.where(r==1)[0][0] for r in complex_v_out_bin])\n",
    "            complex_conf_matrix = metrics.confusion_matrix(truth_int, pred_int)\n",
    "            print(\"complex loss: \", complex_v_loss)\n",
    "            print(\"complex acc:\", complex_v_acc)\n",
    "        \n",
    "        rewrite = 0\n",
    "        if real == 1 and save == 1 and real_v_acc > real_max:\n",
    "            rewrite = 1\n",
    "            real_max = real_v_acc\n",
    "            best_real_conf_matrix = real_conf_matrix\n",
    "            #print(\"real acc:\", real_v_acc)\n",
    "            #print(\"\")\n",
    "            \n",
    "        if complexx == 1 and save == 1 and complex_v_acc > complex_max:\n",
    "            rewrite = 1\n",
    "            complex_max = complex_v_acc\n",
    "            best_complex_conf_matrix = complex_conf_matrix\n",
    "            #print(\"complex acc:\", complex_v_acc)\n",
    "        \n",
    "        if rewrite == 1 and save == 1:\n",
    "            lines = open(f_path, 'r').readlines()\n",
    "            new_last_line = str(real_max)+\",\"+str(complex_max)+\"\\n\"\n",
    "            lines[-1] = new_last_line\n",
    "            open(f_path,'w').writelines(lines)\n",
    "            \n",
    "        for step in range(X_train.shape[0]):\n",
    "            x = np.asarray(X_train[step])\n",
    "            y = np.asarray(y_train[step])\n",
    "            if real == 1:\n",
    "                with tf.GradientTape() as real_tape:\n",
    "                    real_out = real_model(x)\n",
    "                    real_loss = real_loss_fn(y, real_out)\n",
    "                real_grads = real_tape.gradient(real_loss, real_model.trainable_weights)\n",
    "                real_optimizer.apply_gradients(zip(real_grads, real_model.trainable_weights))\n",
    "            if complexx == 1:\n",
    "                with tf.GradientTape() as complex_tape:\n",
    "                    complex_out = complex_model(x)\n",
    "                    complex_loss = complex_loss_fn(y, complex_out)\n",
    "                #print(\"num weights: \", len(complex_model.trainable_weights))\n",
    "                complex_grads = complex_tape.gradient(complex_loss, complex_model.trainable_weights)\n",
    "                #print(\"gradients: \", len(complex_grads))\n",
    "                complex_optimizer.apply_gradients(zip(complex_grads, complex_model.trainable_weights))\n",
    "\n",
    "    if save == 1:\n",
    "        #compute difference-confusion matrix and save\n",
    "        diff_conf_matrix = (diff_conf_matrix * (count-1) + (best_complex_conf_matrix - best_real_conf_matrix))/count\n",
    "        diff_conf_matrix_flat = diff_conf_matrix.flatten('C')\n",
    "        #print(\"flat: \", diff_conf_matrix_flat)\n",
    "        lines = open(f_path_matrix, 'r').readlines()\n",
    "        new_last_line = ','.join(['%.5f' % num for num in diff_conf_matrix_flat])+\"\\n\"\n",
    "        lines[-1] = new_last_line\n",
    "        open(f_path_matrix,'w').writelines(lines)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [30,30,30,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing cell\n",
    "#%%capture output\n",
    "real = 1\n",
    "complexx = 1\n",
    "count = 0\n",
    "graph = 0\n",
    "loss = 0\n",
    "out = 0\n",
    "limit = 100\n",
    "real_loss = []\n",
    "complex_loss = []\n",
    "while(count < limit):\n",
    "    real_max = 0\n",
    "    complex_max = 0\n",
    "    epochs = 60\n",
    "\n",
    "    if complexx == 1:\n",
    "        print(\"made new network\")\n",
    "        complex_model = RealFC(dims)\n",
    "        complex_optimizer = Cadam()\n",
    "        complex_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    if real == 1:\n",
    "        real_model = tf.keras.models.Sequential()\n",
    "        for i in dims[:-1]:\n",
    "            real_model.add(tf.keras.layers.Dense(units=i,activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "            #real_model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "            real_model.add(tf.keras.layers.ReLU())\n",
    "            real_model.add(tf.keras.layers.BatchNormalization())\n",
    "        real_model.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
    "        real_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        real_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        X_train = train_images\n",
    "        y_train = train_labels\n",
    "        shuffler = np.random.permutation(len(X_train))\n",
    "        X_train = X_train[shuffler]\n",
    "        y_train = y_train[shuffler]\n",
    "        batches = train_images.shape[0]//50\n",
    "        if X_train.ndim == 3:\n",
    "            X_train = X_train.reshape(batches,X_train.shape[0]//batches,X_train.shape[1]*X_train.shape[2])\n",
    "        elif X_train.ndim == 2:\n",
    "            X_train = X_train.reshape(batches,X_train.shape[0]//batches,X_train.shape[1])\n",
    "        X_train = (X_train/256.0).astype('float32')\n",
    "        y_temp = np.zeros((y_train.size, int(y_train.max())+1))\n",
    "        y_temp[np.arange(y_train.size),y_train] = 1\n",
    "        y_train = y_temp.reshape(batches,y_temp.shape[0]//batches,y_temp.shape[1])\n",
    "        #validate:\n",
    "        print(\"----------epoch: \", epoch,\"------------------\")\n",
    "        if real == 1:\n",
    "            real_v_out = real_model(X_test[0])\n",
    "            real_v_loss = real_loss_fn(y_test[0], real_v_out)\n",
    "            real_v_out_bin = real_v_out.numpy()\n",
    "            real_v_out_bin = (real_v_out_bin == real_v_out_bin.max(axis=1, keepdims=1)).astype(float)\n",
    "            #real_v_ap = metrics.average_precision_score(y_test[0],real_v_out.numpy())\n",
    "            real_v_acc = metrics.accuracy_score(y_test[0],real_v_out_bin)\n",
    "            print(\"real loss: \", real_v_loss)\n",
    "            print(\"real acc:\", real_v_acc)\n",
    "            \n",
    "        if complexx == 1:\n",
    "            complex_v_out = complex_model(X_test[0])\n",
    "            complex_v_out_bin = complex_v_out.numpy()\n",
    "            complex_v_out_bin = (complex_v_out_bin == complex_v_out_bin.max(axis=1, keepdims=1)).astype(float)\n",
    "            complex_v_loss = complex_loss_fn(y_test[0], complex_v_out)\n",
    "            #complex_v_ap = metrics.average_precision_score(y_test[0],complex_v_out.numpy())\n",
    "            complex_v_acc = metrics.accuracy_score(y_test[0],complex_v_out_bin)\n",
    "            print(\"complex loss: \", complex_v_loss)\n",
    "            print(\"complex acc:\", complex_v_acc)\n",
    "        \n",
    "        rewrite = 0\n",
    "        if real_v_acc > real_max:\n",
    "            rewrite = 1\n",
    "            real_max = real_v_acc\n",
    "            #print(\"real acc:\", real_v_acc)\n",
    "            #print(\"\")\n",
    "            \n",
    "        if complex_v_acc > complex_max:\n",
    "            rewrite = 1\n",
    "            complex_max = complex_v_acc\n",
    "            #print(\"complex acc:\", complex_v_acc)\n",
    "            \n",
    "        for step in range(X_train.shape[0]):\n",
    "            x = np.asarray(X_train[step])\n",
    "            y = np.asarray(y_train[step])\n",
    "            if real == 1:\n",
    "                with tf.GradientTape() as real_tape:\n",
    "                    real_out = real_model(x)\n",
    "                    real_loss = real_loss_fn(y, real_out)\n",
    "                real_grads = real_tape.gradient(real_loss, real_model.trainable_weights)\n",
    "                print(\"\")\n",
    "                print(\"real_grads: \", real_grads)\n",
    "                print(\"\")\n",
    "                real_optimizer.apply_gradients(zip(real_grads, real_model.trainable_weights))\n",
    "            if complexx == 1:\n",
    "                with tf.GradientTape() as complex_tape:\n",
    "                    complex_out = complex_model(x)\n",
    "                    complex_loss = complex_loss_fn(y, complex_out)\n",
    "                complex_grads = complex_tape.gradient(complex_loss, complex_model.trainable_weights)\n",
    "                complex_optimizer.apply_gradients(zip(complex_grads, complex_model.trainable_weights))\n",
    "            \n",
    "    if graph == 1:\n",
    "        print(\"loss: \", loss)\n",
    "        print(\"out: \", out)\n",
    "        print(\"truth: \", y)\n",
    "    if graph == 1:\n",
    "        ind_X = np.asarray(X_train)[0].T\n",
    "        phase = tf.math.angle(model.layers[0].W).numpy()\n",
    "        print(phase)\n",
    "        num_items = phase.shape[0]*phase.shape[1]\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        color = 'b'\n",
    "        zero_color = 'g'\n",
    "        col = 0\n",
    "        while(col < ind_X.shape[1]):\n",
    "            row = 0\n",
    "            if col == 0:\n",
    "                color = 'b'\n",
    "            else:\n",
    "                color = 'r'\n",
    "            while(row < ind_X.shape[0]):\n",
    "                #print(phase.item(c))\n",
    "                if ind_X[row][col]> 0.0:\n",
    "                    plt.plot(phase[row][col],5, 'ro', ms = 15, mfc = color)\n",
    "                else:\n",
    "                    plt.plot(phase[row][col],5, 'ro', ms = 15, mfc = zero_color)\n",
    "                row += 1\n",
    "            col += 1\n",
    "        plt.show()\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_max)\n",
    "print(complex_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train = [[[0., 1., 1., 0., 1.], [1., 0., 0., 1., 0.]]]\n",
    "y_train = [[[1., 0.], [0., 1.]]]\n",
    "samples_per_batch = len(X_train[0])\n",
    "features = len(X_train[0][0])\n",
    "'''\n",
    "ind_X = np.asarray(X_train)[0].T\n",
    "phase = tf.math.angle(model.layers[0].W).numpy()\n",
    "print(phase)\n",
    "num_items = phase.shape[0]*phase.shape[1]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "c = 0\n",
    "while(c < num_items):\n",
    "    #print(phase.item(c))\n",
    "    if ind_X.item(c) > 0.0:\n",
    "        plt.plot(phase.item(c),5, 'ro', ms = 15, mfc = 'b')\n",
    "    else:\n",
    "        plt.plot(phase.item(c),5, 'ro', ms = 15, mfc = 'r')\n",
    "    c += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### print(np.asarray(X_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = 0\n",
    "def analysis2(y_hat, y):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y, y_hat)\n",
    "    return precision,recall,thresholds\n",
    "    \n",
    "def AP(y_hat, y):\n",
    "    ap = metrics.average_precision_score(y, y_hat)\n",
    "    return ap\n",
    "\n",
    "def validate(model, data_generator_valid):\n",
    "    epoch: int = 0\n",
    "    num_epochs = 1\n",
    "    pbar_msg: str = \"epoch [{0}/{1}] {2:.3f}% loss: {3:.3f}\"\n",
    "    num_batch = int(data_generator_valid.__len__())\n",
    "    valid_y_hat_all = None\n",
    "    valid_y_all = None\n",
    "    while epoch < num_epochs: # and any other halting criteria is not met\n",
    "\n",
    "        # training loop\n",
    "        epoch_loss = None\n",
    "        num_examples_processed: int = 0\n",
    "        for batch_id in range(int(data_generator_valid.__len__())):\n",
    "            X_valid_batch, Y_valid_gt = data_generator_valid[batch_id]\n",
    "\n",
    "            batch_loss = None\n",
    "            y_valid_hat = model(X_valid_batch)\n",
    "            if valid_y_hat_all == None:\n",
    "                valid_y_hat_all = y_valid_hat\n",
    "                valid_y_all = Y_valid_gt\n",
    "            else:\n",
    "                valid_y_hat_all = tf.concat([valid_y_hat_all, y_valid_hat], axis = 0)\n",
    "                valid_y_all = tf.concat([valid_y_all, Y_valid_gt], axis = 0)\n",
    "            #print(\"valid shape check: \", valid_y_hat_all.shape)\n",
    "            #print(\"gt shape check: \", valid_y_all.shape)\n",
    "            batch_valid_loss = loss(Y_valid_gt, y_valid_hat)\n",
    "            #print(\"loss: \", batch_loss)\n",
    "\n",
    "            if epoch_loss is None:\n",
    "                epoch_loss = batch_valid_loss * X_valid_batch.shape[0]\n",
    "            else:\n",
    "                epoch_loss += batch_valid_loss * X_valid_batch.shape[0]\n",
    "\n",
    "\n",
    "        epoch += 1\n",
    "    y_flat = valid_y_all.numpy().flatten()\n",
    "    y_hat_flat = valid_y_hat_all.numpy().flatten()\n",
    "    print(\"Average Precision: \", AP(y_hat_flat, y_flat))\n",
    "    if plot == 1:\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(y_flat, y_hat_flat)\n",
    "        plt.plot(recall, precision)\n",
    "        plt.xlabel('recall')\n",
    "        plt.ylabel('precision')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch):\n",
    "    if epoch >= 0 and epoch < 10:\n",
    "        lrate = 1e-3\n",
    "        #if epoch == 0:\n",
    "        #    print('\\ncurrent learning rate value is ' + str(lrate))\n",
    "    elif epoch >= 10 and epoch < 100:\n",
    "        lrate = 1e-4\n",
    "        #if epoch == 10:\n",
    "        #    print('\\ncurrent learning rate value is ' + str(lrate))\n",
    "    elif epoch >= 100 and epoch < 120:\n",
    "        lrate = 5e-5\n",
    "        #if epoch == 100:\n",
    "        #    print('\\ncurrent learning rate value is ' + str(lrate))\n",
    "    elif epoch >= 120 and epoch < 150:\n",
    "        lrate = 1e-5\n",
    "        #if epoch == 120:\n",
    "        #    print('\\ncurrent learning rate value is ' + str(lrate))\n",
    "    elif epoch >= 150:\n",
    "        lrate = 1e-6\n",
    "        #if epoch == 150:\n",
    "        #    print('\\ncurrent learning rate value is ' + str(lrate))\n",
    "    return lrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "def train(model,name,complex_real = 0, fpath = None):\n",
    "    epoch: int = 0\n",
    "    num_epochs = 200\n",
    "    pbar_msg: str = \"epoch [{0}/{1}] {2:.3f}% loss: {3:.3f}\"\n",
    "    batch_size = 100\n",
    "    steps_per_epoch = 1000\n",
    "    with tqdm(total=steps_per_epoch) as pbar:\n",
    "        while epoch < num_epochs: # and any other halting criteria is not met\n",
    "            print(\"Epoch: \", epoch)\n",
    "            pbar.reset()\n",
    "            step = 0\n",
    "            epoch_loss = None\n",
    "            num_examples_processed: int = 0\n",
    "            while(step < steps_per_epoch):\n",
    "                if complex_real == 0:\n",
    "                    model.training = True\n",
    "                    X_batch, Y_gt = next(it)\n",
    "                    #print(X_batch)\n",
    "                    X_batch = tf.cast(X_batch,dtype='complex64')\n",
    "                    Y_gt = tf.convert_to_tensor(Y_gt)\n",
    "                    #print(\"X_batch: \", X_batch.shape)\n",
    "                    y_hat = None\n",
    "                    batch_loss = None\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_hat = model(X_batch)\n",
    "                        batch_loss = loss(Y_gt, y_hat)\n",
    "                    grads = tape.gradient(batch_loss, model.trainable_weights)\n",
    "                    optimizer.learning_rate = schedule(epoch)\n",
    "                    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "                    if epoch_loss is None:\n",
    "                        epoch_loss = batch_loss * X_batch.shape[0]\n",
    "                    else:\n",
    "                        epoch_loss += batch_loss * X_batch.shape[0]\n",
    "                    num_examples_processed += X_batch.shape[0]\n",
    "                    pbar.set_description(pbar_msg.format(epoch, num_epochs,\n",
    "                                          epoch/num_epochs*100,\n",
    "                                          epoch_loss / num_examples_processed))\n",
    "                    pbar.update(1)\n",
    "                    if step == 0:\n",
    "                        model.training = False\n",
    "                        dataset: MusicNetData = MusicNetData('./Data/train_val/test_x.npz','./Data/train_val/test_y.npz', 'test_x', 'test_y')\n",
    "                        print(\"Created valid dataset\")\n",
    "                        data_generator: MusicNetGenerator = MusicNetGenerator(dataset,100)\n",
    "                        print(\"created valid generator\")\n",
    "                        print(\"VALIDATING\")\n",
    "                        validate(model, data_generator)\n",
    "                        if (epoch+1)%5 == 0:\n",
    "                            model.save_weights('./weights/'+name+'.ckpt')\n",
    "                else:\n",
    "                    dataset: MusicNetData = MusicNetDataReal('./Data/train_x_'+str(cur_file)+'.npz','./Data/train_y_'+str(cur_file)+'.npz', 'train_x', 'train_y')\n",
    "                    data_generator: MusicNetGeneratorReal = MusicNetGeneratorReal(dataset,batch_size)\n",
    "                    for batch_id in range(int(data_generator.__len__())):\n",
    "                        #print(\"batch: \", batch_id, \"of \", int(data_generator.__len__()))\n",
    "                        X_batch, Y_gt = data_generator[batch_id]\n",
    "                        #print(\"Xbatch: \", X_batch.shape)\n",
    "                        hist = model.fit(X_batch, Y_gt, batch_size = None, verbose = 0)\n",
    "                        batch_loss = hist.history['loss'][0]\n",
    "                        if epoch_loss is None:\n",
    "                            epoch_loss = batch_loss * X_batch.shape[0]\n",
    "                        else:\n",
    "                            epoch_loss += batch_loss * X_batch.shape[0]\n",
    "                        num_examples_processed += X_batch.shape[0]\n",
    "                        pbar.set_description(pbar_msg.format(epoch, num_epochs,\n",
    "                                              epoch/num_epochs*100,\n",
    "                                              epoch_loss / num_examples_processed))\n",
    "                        pbar.update(1)\n",
    "\n",
    "                    if (epoch+1)%5 == 0 and step == 0:\n",
    "                        dataset: MusicNetDataReal = MusicNetDataReal('./Data/test_x.npz','./Data/test_y.npz', 'test_x', 'test_y')\n",
    "                        print(\"Created valid dataset\")\n",
    "                        data_generator: MusicNetGeneratorReal = MusicNetGeneratorReal(dataset,100)\n",
    "                        print(\"created valid generator\")\n",
    "                        print(\"VALIDATING\")\n",
    "                        validate(model, data_generator)\n",
    "                step += 1\n",
    "            epoch += 1\n",
    "                    # TODO: validation loop\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real network initialization\n",
    "model = RealFC([2048,1024,512,400], [300,200,100,84])\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network shape:\n",
    "1 = [2048,1024,800,600,512,400], [400,300,200,100,84]\n",
    "2 = [2048,1024,512,400], [400,200,84]\n",
    "3 = [2048,1024,800,512,400], [400,200,84]\n",
    "4 = [2048,1024,800,512,400], [600,400,200,84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complex initialization\n",
    "fpath = './Data/train_val'\n",
    "optimizer = Cadam(lr=.001)\n",
    "regu = {}\n",
    "regu['dropout'] = 0.05\n",
    "regu['c_dropout'] = 0.05\n",
    "regu['batchnorm'] = 1.0\n",
    "model = ComplexFC(regu, [2048,1024,800,512,400], [400,200,84])\n",
    "n_type = \"3\"\n",
    "loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture output\n",
    "train(model, name=\"Lr1e-3Network\"+n_type+\"TypeFcDroutput\"+str(regu['c_dropout'])+\",\"+str(regu['dropout'])+\"FullData\",complex_real = 0, fpath = fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv network shape:\n",
    "each tuple is: (filters, kernel_size, stride,)\n",
    "1. [(3,6,1), (3,6,1), (3,6,1)],[400,200,84]\n",
    "1. [(8,6,1), (16,6,1), (32,6,1)],[400,200,84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Complex convolutional initialization\n",
    "fpath = './Data/train_val'\n",
    "optimizer = Cadam(lr=.001)\n",
    "regu = {}\n",
    "regu['dropout'] = 0.2\n",
    "regu['c_dropout'] = 0.05\n",
    "regu['batchnorm'] = 1.0\n",
    "model = ConvNN(regu,[(16,4,1), (32,4,1), (32,4,1)],[400,200,84])\n",
    "n_type = \"2\"\n",
    "loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture output\n",
    "train(model, name=\"Lr1e-3Network\"+n_type+\"TypeCNNDroutput\"+str(regu['c_dropout'])+\",\"+str(regu['dropout'])+\"FullData\",complex_real = 0, fpath = fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biofc initialization\n",
    "fpath = './Data/train_val'\n",
    "optimizer = Cadam(lr=.001)\n",
    "regu = {}\n",
    "regu['dropout'] = 0.5\n",
    "regu['batchnorm'] = 1.0\n",
    "model = biofc(regu, [2048,1024,800,512,400], [600,400,200,84])\n",
    "loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "train(model, name=\"Lr1e-3Network4TypeFcDroutput0.5FullDataBio\",complex_real = 0, fpath = fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complex net testing\n",
    "regu = {}\n",
    "regu['dropout'] = 0.5\n",
    "regu['batchnorm'] = 1.0\n",
    "model = ComplexFC(regu, [2048,1024,800,512,400], [600,400,200,84])\n",
    "#model.load_weights('./weights/Lr1e-3Network4TypeFc.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights/Lr1e-3Network4TypeFcDroutput0.5FullData.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: MusicNetData = MusicNetData('./Data/train_val/test_x.npz','./Data/train_val/test_y.npz', 'test_x', 'test_y')\n",
    "data_generator: MusicNetGenerator = MusicNetGenerator(dataset,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(None)\n",
    "idd = random.randint(0,5000)\n",
    "print(idd)\n",
    "x, y = data_generator[idd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y = next(it)\n",
    "#x = tf.cast(x,dtype='complex64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = y_hat.numpy()[(np.where(y > 0))]\n",
    "zeros = y_hat.numpy()[(np.where(y == 0))]\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(ones, ones, s=10, c='b', marker=\"s\", label='pos')\n",
    "ax1.scatter(zeros, zeros, s=10, c='r', marker=\"o\", label='neg')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### X_batch, Y_gt = next(it)\n",
    "X_batch = tf.cast(X_batch,dtype='complex64')\n",
    "Y_gt = tf.convert_to_tensor(Y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: MusicNetData = MusicNetData('./Data/train_val/test_x.npz','./Data/train_val/test_y.npz', 'test_x', 'test_y')\n",
    "print(\"Created valid dataset\")\n",
    "data_generator: MusicNetGenerator = MusicNetGenerator(dataset)\n",
    "print(\"created valid generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data = \"/scratch/ryu1/deep_complex_networks2017/musicnet/scripts/data/musicnet_11khz.npz\"\n",
    "rng = np.random.RandomState(123)\n",
    "\n",
    "dataset = MusicNet(local_data, complex_= True, fourier=True,\n",
    "                           stft=False, rng=rng, fast_load=True)\n",
    "dataset.load()\n",
    "\n",
    "Xtest, Ytest = dataset.eval_set('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.cast(Xtest, dtype='complex64')\n",
    "#Y_gt = tf.convert_to_tensor(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, Y_gt = data_generator[0]\n",
    "pr2 = model(X).numpy()\n",
    "orig_shape = pr2.shape\n",
    "pr2 = pr2.flatten()\n",
    "print(pr2)\n",
    "thresh = 0.6\n",
    "pr2 = [0 if a < thresh else 1 for a in pr2]\n",
    "pr2 = np.reshape(pr2, orig_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pr2[:200, 10:65].T)\n",
    "plt.yticks(list(range(10, 65, 10)))\n",
    "plt.ylabel('Note ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y_gt[:200, 10:65].T)\n",
    "plt.yticks(list(range(10, 65, 10)))\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Note ID')\n",
    "plt.savefig(\"pred_gt.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.cast(np.random.random((10,4096)) + 1j*np.random.random((10,4096)),dtype='complex64')\n",
    "\n",
    "print(model(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: MusicNetDataReal = MusicNetData('./Data/test_x.npz','./Data/test_y.npz', 'test_x', 'test_y')\n",
    "print(\"Created valid dataset\")\n",
    "data_generator: MusicNetGenerator = MusicNetGenerator(dataset)\n",
    "print(\"created valid generator\")\n",
    "print(\"VALIDATING\")\n",
    "validate(model, data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './Data/train_val'\n",
    "cur_file = 0\n",
    "batch_size = 100\n",
    "dataset: MusicNetData = MusicNetData(fpath+os.sep+'train_x_'+str(cur_file)+'.npz',fpath+os.sep+'train_y_'+str(cur_file)+'.npz', 'train_x', 'train_y')\n",
    "data_generator: MusicNetGenerator = MusicNetGenerator(dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './Data/val_val'\n",
    "cur_file = 0\n",
    "batch_size = 100\n",
    "dataset1: MusicNetData = MusicNetData(fpath+os.sep+'train_x_'+str(cur_file)+'.npz',fpath+os.sep+'train_y_'+str(cur_file)+'.npz', 'train_x', 'train_y')\n",
    "data_generator1: MusicNetGenerator = MusicNetGenerator(dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "def train(model,complex_real = 0, fpath = None):\n",
    "    epoch: int = 0\n",
    "    num_epochs = 40\n",
    "    pbar_msg: str = \"epoch [{0}/{1}] {2:.3f}% loss: {3:.3f}\"\n",
    "    batch_size = 100\n",
    "    num_samples = 80000\n",
    "    total_files = 8\n",
    "    num_batch = num_samples//batch_size\n",
    "    with tqdm(total=num_batch) as pbar:\n",
    "        while epoch < num_epochs: # and any other halting criteria is not met\n",
    "            print(\"Epoch: \", epoch)\n",
    "            pbar.reset()\n",
    "            cur_file = 0\n",
    "            epoch_loss = None\n",
    "            num_examples_processed: int = 0\n",
    "            while(cur_file < total_files):\n",
    "                dataset = None\n",
    "                data_generator = None\n",
    "                if complex_real == 0:\n",
    "                    dataset: MusicNetData = MusicNetData(fpath+os.sep+'train_x_'+str(cur_file)+'.npz',fpath+os.sep+'train_y_'+str(cur_file)+'.npz', 'train_x', 'train_y')\n",
    "                    data_generator: MusicNetGenerator = MusicNetGenerator(dataset,batch_size)\n",
    "                    for batch_id in range(int(data_generator.__len__())):\n",
    "                        X_batch, Y_gt = data_generator[batch_id]\n",
    "                        #print(\"X_batch: \", X_batch.shape)\n",
    "                        y_hat = None\n",
    "                        batch_loss = None\n",
    "                        with tf.GradientTape() as tape:\n",
    "                            y_hat = model(X_batch)\n",
    "                            batch_loss = loss(Y_gt, y_hat)\n",
    "                        grads = tape.gradient(batch_loss, model.trainable_weights)\n",
    "                        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "                        if epoch_loss is None:\n",
    "                            epoch_loss = batch_loss * X_batch.shape[0]\n",
    "                        else:\n",
    "                            epoch_loss += batch_loss * X_batch.shape[0]\n",
    "                        num_examples_processed += X_batch.shape[0]\n",
    "                        pbar.set_description(pbar_msg.format(epoch, num_epochs,\n",
    "                                              epoch/num_epochs*100,\n",
    "                                              epoch_loss / num_examples_processed))\n",
    "                        pbar.update(1)\n",
    "                    if (epoch+1)%5 == 0 and cur_file == 0:\n",
    "                        dataset: MusicNetData = MusicNetData('./Data/train_val/test_x.npz','./Data/train_val/test_y.npz', 'test_x', 'test_y')\n",
    "                        print(\"Created valid dataset\")\n",
    "                        data_generator: MusicNetGenerator = MusicNetGenerator(dataset)\n",
    "                        print(\"created valid generator\")\n",
    "                        print(\"VALIDATING\")\n",
    "                        validate(model, data_generator)\n",
    "                else:\n",
    "                    dataset: MusicNetData = MusicNetDataReal('./Data/train_x_'+str(cur_file)+'.npz','./Data/train_y_'+str(cur_file)+'.npz', 'train_x', 'train_y')\n",
    "                    data_generator: MusicNetGeneratorReal = MusicNetGeneratorReal(dataset,batch_size)\n",
    "                    for batch_id in range(int(data_generator.__len__())):\n",
    "                        #print(\"batch: \", batch_id, \"of \", int(data_generator.__len__()))\n",
    "                        X_batch, Y_gt = data_generator[batch_id]\n",
    "                        #print(\"Xbatch: \", X_batch.shape)\n",
    "                        hist = model.fit(X_batch, Y_gt, batch_size = None, verbose = 0)\n",
    "                        batch_loss = hist.history['loss'][0]\n",
    "                        if epoch_loss is None:\n",
    "                            epoch_loss = batch_loss * X_batch.shape[0]\n",
    "                        else:\n",
    "                            epoch_loss += batch_loss * X_batch.shape[0]\n",
    "                        num_examples_processed += X_batch.shape[0]\n",
    "                        pbar.set_description(pbar_msg.format(epoch, num_epochs,\n",
    "                                              epoch/num_epochs*100,\n",
    "                                              epoch_loss / num_examples_processed))\n",
    "                        pbar.update(1)\n",
    "                        \n",
    "                    if (epoch+1)%5 == 0 and cur_file == 0:\n",
    "                        dataset: MusicNetDataReal = MusicNetDataReal('./Data/test_x.npz','./Data/test_y.npz', 'test_x', 'test_y')\n",
    "                        print(\"Created valid dataset\")\n",
    "                        data_generator: MusicNetGeneratorReal = MusicNetGeneratorReal(dataset)\n",
    "                        print(\"created valid generator\")\n",
    "                        print(\"VALIDATING\")\n",
    "                        validate(model, data_generator)\n",
    "                cur_file += 1\n",
    "            epoch += 1\n",
    "                    # TODO: validation loop\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_file = 0\n",
    "batch_size = 100\n",
    "dataset: MusicNetData = MusicNetDataReal('./Data/train_x_'+str(cur_file)+'.npz','./Data/train_y_'+str(cur_file)+'.npz', 'train_x', 'train_y')\n",
    "data_generator: MusicNetGeneratorReal = MusicNetGeneratorReal(dataset,batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
